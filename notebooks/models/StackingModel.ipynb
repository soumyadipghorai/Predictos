{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-dCTiJeOq9j5"
      },
      "outputs": [],
      "source": [
        "# handling data \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "# warnings\n",
        "import warnings\n",
        "pd.options.mode.chained_assignment = None \n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import pickle "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('model_data.pkl', 'rb')\n",
        "data = pickle.load(file)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "Wao_qi-7rMWo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Log "
      ],
      "metadata": {
        "id": "MEIsJYR8uYZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = data['x_train_log']\n",
        "x_test = data['x_test_log']\n",
        "y_train = data['y_train_log']\n",
        "y_test = data['y_test_log']"
      ],
      "metadata": {
        "id": "4mQPXCnGrV1E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model_log = pickle.load(open('RandomForestRegressorLog.pkl', 'rb'))\n",
        "ridge_model_log = pickle.load(open('RidgeRegressionLog.pkl', 'rb'))\n",
        "svr_model_log = pickle.load(open('SupportVectorRegressorLog.pkl', 'rb'))\n",
        "xgb_model_log = pickle.load(open('XGBRegressorLog.pkl', 'rb'))\n",
        "dtr_model_log = pickle.load(open('DecisionTreeLog.pkl', 'rb'))\n",
        "knn_model_log = pickle.load(open('KNeighborsRegressorLog.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "YgNJ648wrepP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8567d1b-a51c-4295-c18d-2e2636a5d175"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16:46:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "    # ('rf_model_log', rf_model_log), \n",
        "    ('ridge_model_log', ridge_model_log), \n",
        "    ('svr_model_log', svr_model_log),\n",
        "    ('xgb_model_log', xgb_model_log),\n",
        "    ('knn_model_log', knn_model_log)\n",
        "]"
      ],
      "metadata": {
        "id": "TbUqqZNFr-_M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = StackingRegressor(\n",
        "    estimators = estimators, \n",
        "    final_estimator = RandomForestRegressor(n_estimators = 15, random_state = 42)\n",
        ")"
      ],
      "metadata": {
        "id": "EbrMQfmvse_W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5zezahWtLdk",
        "outputId": "b94d0a25-5a9a-4956-99a5-1aecd55e0e08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.611 total time=   4.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.617 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.609 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.620 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.556 total time=   3.9s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.635 total time=   3.3s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.621 total time=   3.2s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.599 total time=   3.3s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.644 total time=   3.3s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.580 total time=   3.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.631 total time=   3.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.668 total time=   2.4s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.648 total time=   2.4s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.659 total time=   2.4s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.594 total time=   2.4s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.616 total time=   5.0s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   5.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.612 total time=   5.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.625 total time=   5.0s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.560 total time=   5.2s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.614 total time=   7.2s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.619 total time=   6.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.611 total time=   6.2s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.622 total time=   6.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.558 total time=   6.4s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.603 total time=   3.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.607 total time=   3.9s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.600 total time=   3.9s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.613 total time=   3.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.549 total time=   3.9s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.672 total time=   4.2s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.719 total time=   4.2s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.700 total time=   4.2s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.704 total time=   4.2s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.640 total time=   4.2s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.617 total time=   3.7s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.619 total time=   3.7s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.611 total time=   3.7s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.624 total time=   3.7s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.560 total time=   3.7s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.615 total time=   2.8s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   2.8s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.612 total time=   2.8s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.625 total time=   2.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.560 total time=   2.9s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.606 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.621 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.609 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.620 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.555 total time=   3.9s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.193 total time=   0.7s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.271 total time=   0.7s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.080 total time=   0.7s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.043 total time=   0.7s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.158 total time=   0.7s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.549 total time=   0.3s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.714 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.190 total time=   0.3s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.064 total time=   0.3s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.474 total time=   0.3s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.461 total time=   3.4s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.473 total time=   3.4s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.475 total time=   3.4s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.487 total time=   3.4s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.481 total time=   3.4s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.598 total time=   0.3s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.751 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.217 total time=   0.3s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.067 total time=   0.3s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.485 total time=   0.3s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.547 total time=   0.3s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.700 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.188 total time=   0.3s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.063 total time=   0.3s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.455 total time=   0.3s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.218 total time=   0.6s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.290 total time=   0.5s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.092 total time=   0.5s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.065 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.186 total time=   0.5s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.364 total time=   2.5s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.386 total time=   2.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.357 total time=   2.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.388 total time=   2.4s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.362 total time=   2.4s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.382 total time=   2.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.400 total time=   2.2s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.370 total time=   2.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.404 total time=   2.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.377 total time=   2.2s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.344 total time=   1.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.361 total time=   1.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.346 total time=   1.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.388 total time=   1.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.343 total time=   2.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.176 total time=   0.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.262 total time=   0.8s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.066 total time=   0.9s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.030 total time=   0.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.145 total time=   0.8s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.670 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.575 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.634 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.614 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.630 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.576 total time=   0.5s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.529 total time=   0.4s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.562 total time=   0.4s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.548 total time=   0.4s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.548 total time=   0.4s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.588 total time=   0.2s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.558 total time=   0.2s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.558 total time=   0.2s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.559 total time=   0.2s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.565 total time=   0.2s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.738 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.632 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.684 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.677 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.703 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.594 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.555 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.585 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.568 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.581 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.618 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.564 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.589 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.559 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.587 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.607 total time=   0.4s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.570 total time=   0.4s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.594 total time=   0.4s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.562 total time=   0.4s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.592 total time=   0.4s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.618 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.564 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.589 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.559 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.587 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.627 total time=   0.4s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.571 total time=   0.4s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.607 total time=   0.4s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.575 total time=   0.4s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.601 total time=   0.4s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.739 total time=   0.1s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.632 total time=   0.1s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.688 total time=   0.1s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.676 total time=   0.1s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.709 total time=   0.1s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.639 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.581 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.626 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.619 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.553 total time=   2.6s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.657 total time=   2.1s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.572 total time=   2.1s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.636 total time=   2.2s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.656 total time=   2.1s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.569 total time=   2.2s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.691 total time=   1.5s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.615 total time=   1.5s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.705 total time=   1.5s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.651 total time=   1.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.570 total time=   1.5s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.642 total time=   3.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.586 total time=   3.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.628 total time=   3.4s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.623 total time=   3.4s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.557 total time=   3.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.639 total time=   4.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.584 total time=   4.0s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.634 total time=   4.2s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.619 total time=   4.2s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.552 total time=   4.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.633 total time=   2.6s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.570 total time=   2.6s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.621 total time=   2.6s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.613 total time=   2.6s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.545 total time=   2.6s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.736 total time=   2.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.661 total time=   2.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.766 total time=   2.7s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.690 total time=   2.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.606 total time=   2.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.640 total time=   2.5s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.585 total time=   2.4s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.630 total time=   2.4s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.622 total time=   2.5s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.556 total time=   2.5s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.642 total time=   1.8s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.586 total time=   1.8s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.628 total time=   1.8s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.623 total time=   1.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.557 total time=   1.8s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.641 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.577 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.635 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.615 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.543 total time=   2.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.604 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.602 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.627 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.619 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.544 total time=   2.6s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.645 total time=   2.1s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.588 total time=   2.1s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.632 total time=   2.1s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.662 total time=   2.1s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.556 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.635 total time=   1.5s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.631 total time=   1.5s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.710 total time=   1.5s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.656 total time=   1.5s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.569 total time=   1.5s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.608 total time=   3.5s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.607 total time=   4.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.629 total time=   3.4s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.622 total time=   3.4s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.547 total time=   3.4s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.608 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.605 total time=   4.0s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.635 total time=   4.0s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.619 total time=   4.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.545 total time=   4.0s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.598 total time=   2.5s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.593 total time=   2.6s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.621 total time=   2.6s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.611 total time=   2.5s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.537 total time=   2.6s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.668 total time=   2.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.670 total time=   2.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.766 total time=   2.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.690 total time=   2.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.606 total time=   2.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.608 total time=   2.4s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.606 total time=   2.4s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.631 total time=   2.4s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.621 total time=   2.4s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.546 total time=   2.5s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.608 total time=   1.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.607 total time=   1.9s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.629 total time=   1.8s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.622 total time=   1.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.547 total time=   1.8s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.600 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.600 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.639 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.617 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.539 total time=   2.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.606 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.616 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.629 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.618 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.550 total time=   2.6s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.647 total time=   2.1s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.627 total time=   2.2s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.629 total time=   2.2s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.651 total time=   2.1s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.564 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.632 total time=   1.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.660 total time=   1.5s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.708 total time=   1.5s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.654 total time=   1.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.570 total time=   1.5s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.610 total time=   3.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.617 total time=   3.4s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.631 total time=   3.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.621 total time=   3.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.553 total time=   3.5s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.608 total time=   4.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.615 total time=   4.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.635 total time=   4.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.618 total time=   4.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.551 total time=   4.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.600 total time=   2.6s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.613 total time=   2.6s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.620 total time=   2.6s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.611 total time=   2.6s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.544 total time=   2.6s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.668 total time=   3.6s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.701 total time=   3.0s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.759 total time=   2.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.690 total time=   2.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.606 total time=   2.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.610 total time=   2.5s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.616 total time=   2.4s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.633 total time=   2.5s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.620 total time=   2.5s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.551 total time=   2.4s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.610 total time=   1.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.617 total time=   1.8s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.631 total time=   1.9s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   1.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.553 total time=   1.9s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.599 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.615 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.638 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.614 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.542 total time=   2.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.603 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.617 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.607 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.619 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.546 total time=   2.6s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.634 total time=   2.1s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.636 total time=   2.1s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.599 total time=   2.1s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.635 total time=   2.1s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.566 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.631 total time=   1.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.659 total time=   1.5s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.653 total time=   1.5s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.690 total time=   1.5s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.569 total time=   1.6s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.608 total time=   3.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   3.4s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.613 total time=   3.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.621 total time=   3.4s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.550 total time=   3.4s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.606 total time=   4.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.617 total time=   4.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.611 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.626 total time=   4.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.548 total time=   4.0s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.594 total time=   2.6s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.614 total time=   2.6s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.597 total time=   2.6s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.612 total time=   2.6s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.540 total time=   2.6s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.668 total time=   2.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.701 total time=   2.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.701 total time=   2.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.743 total time=   2.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.606 total time=   2.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.607 total time=   2.5s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.619 total time=   2.5s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.611 total time=   2.4s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.622 total time=   2.4s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.549 total time=   2.3s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.608 total time=   1.8s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   1.8s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.613 total time=   1.9s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.621 total time=   1.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.550 total time=   1.8s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.597 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.617 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.609 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.626 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.539 total time=   2.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.609 total time=   3.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.618 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.606 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.620 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-1.629 total time=   2.6s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.648 total time=   2.1s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.618 total time=   2.2s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.601 total time=   2.1s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.617 total time=   2.0s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-1.658 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.631 total time=   1.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.658 total time=   1.5s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.652 total time=   1.5s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.685 total time=   1.5s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-1.655 total time=   1.5s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.613 total time=   3.5s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   3.5s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.610 total time=   3.2s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   3.5s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.633 total time=   3.5s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.610 total time=   4.0s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.617 total time=   4.0s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.608 total time=   4.0s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.624 total time=   4.0s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-1.630 total time=   4.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.601 total time=   2.6s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.615 total time=   2.6s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.595 total time=   2.6s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.615 total time=   2.6s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-1.623 total time=   2.6s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.668 total time=   2.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.701 total time=   2.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.700 total time=   2.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.734 total time=   2.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-1.695 total time=   2.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.614 total time=   2.5s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.619 total time=   2.5s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.609 total time=   2.4s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.621 total time=   2.5s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-1.632 total time=   2.5s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.613 total time=   1.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   1.8s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.610 total time=   1.9s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.620 total time=   1.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-1.633 total time=   1.9s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.600 total time=   2.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.616 total time=   2.6s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.606 total time=   2.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.624 total time=   2.6s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-1.623 total time=   2.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.251 total time=   0.5s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.088 total time=   0.6s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.188 total time=   0.5s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.070 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.191 total time=   0.6s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.638 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.235 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.437 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.177 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.561 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.472 total time=   2.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.519 total time=   2.7s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.551 total time=   2.8s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.521 total time=   2.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.501 total time=   2.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.676 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.298 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.465 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.206 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.579 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.625 total time=   0.3s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.232 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.434 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.184 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.549 total time=   0.3s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.275 total time=   0.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.095 total time=   0.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.215 total time=   0.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.092 total time=   0.4s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.210 total time=   0.4s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.397 total time=   1.9s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.366 total time=   1.9s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.384 total time=   2.0s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.380 total time=   1.9s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.368 total time=   2.0s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.405 total time=   1.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.379 total time=   1.8s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.395 total time=   1.8s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.394 total time=   1.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.389 total time=   1.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.372 total time=   1.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.357 total time=   1.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.366 total time=   1.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.370 total time=   1.3s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.370 total time=   1.8s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.239 total time=   0.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.071 total time=   0.7s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.175 total time=   0.6s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.063 total time=   0.7s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.185 total time=   1.2s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.222 total time=   0.5s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.042 total time=   0.5s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.199 total time=   0.5s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.083 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.202 total time=   0.5s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.687 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.036 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.455 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.214 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.585 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.450 total time=   2.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.545 total time=   2.7s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.525 total time=   2.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.503 total time=   2.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.531 total time=   2.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.741 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.076 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.471 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.224 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.593 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.669 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.042 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.448 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.212 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.568 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.246 total time=   0.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.050 total time=   0.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.227 total time=   0.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.105 total time=   0.4s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.219 total time=   0.4s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.358 total time=   1.9s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.383 total time=   1.9s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.393 total time=   1.9s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.385 total time=   1.9s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.361 total time=   1.9s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.370 total time=   1.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.390 total time=   1.8s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.402 total time=   1.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.403 total time=   1.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.386 total time=   1.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.338 total time=   1.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.372 total time=   1.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.368 total time=   1.1s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.385 total time=   1.1s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.353 total time=   1.1s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.205 total time=   0.6s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.031 total time=   0.6s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.188 total time=   0.6s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.078 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.195 total time=   0.7s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.179 total time=   0.6s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.035 total time=   0.5s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.363 total time=   0.5s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.047 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.169 total time=   0.5s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.579 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.071 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.907 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.111 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.497 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.479 total time=   2.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.497 total time=   2.7s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.550 total time=   2.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.479 total time=   2.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.538 total time=   2.7s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.640 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.078 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.954 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.138 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.520 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.560 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.065 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.903 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.112 total time=   0.3s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.487 total time=   0.3s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.205 total time=   0.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.058 total time=   0.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.383 total time=   0.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.067 total time=   0.4s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.188 total time=   0.4s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.359 total time=   1.9s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.379 total time=   1.9s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.426 total time=   1.9s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.367 total time=   2.0s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.364 total time=   2.0s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.375 total time=   1.7s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.390 total time=   1.8s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.438 total time=   1.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.387 total time=   1.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.384 total time=   1.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.348 total time=   1.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.373 total time=   1.1s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.403 total time=   1.1s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.358 total time=   1.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.362 total time=   1.1s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.162 total time=   0.6s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.031 total time=   0.6s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.351 total time=   0.6s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.037 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.161 total time=   0.7s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.166 total time=   0.6s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.025 total time=   0.5s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.225 total time=   0.5s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.216 total time=   0.5s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.156 total time=   0.5s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.575 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.059 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.557 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.576 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.467 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.453 total time=   2.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.516 total time=   2.7s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.539 total time=   2.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.533 total time=   2.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.551 total time=   2.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.612 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.058 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.610 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.603 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.489 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.557 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.059 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.556 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.575 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.461 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.197 total time=   0.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.046 total time=   0.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.235 total time=   0.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.240 total time=   0.4s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.170 total time=   0.4s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.346 total time=   1.9s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.374 total time=   2.0s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.406 total time=   1.9s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.359 total time=   1.9s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.368 total time=   2.0s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.363 total time=   1.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.385 total time=   1.8s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.420 total time=   1.8s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.363 total time=   1.7s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.389 total time=   1.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.330 total time=   1.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.367 total time=   1.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.399 total time=   1.1s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.335 total time=   1.1s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.351 total time=   1.1s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.150 total time=   0.7s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.026 total time=   0.6s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.216 total time=   0.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.203 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.151 total time=   0.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.195 total time=   0.6s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.057 total time=   0.6s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.236 total time=   0.6s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.302 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-5.969 total time=   0.6s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.634 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.129 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.626 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.837 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-35.863 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.479 total time=   2.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.531 total time=   2.8s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.521 total time=   2.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.538 total time=   2.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.529 total time=   2.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.675 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.139 total time=   0.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.672 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-36.878 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=-35.860 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.624 total time=   0.2s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.121 total time=   0.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.624 total time=   0.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-36.832 total time=   0.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=-35.863 total time=   0.2s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.226 total time=   0.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.083 total time=   0.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.246 total time=   0.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.331 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-5.987 total time=   0.7s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.354 total time=   2.5s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.374 total time=   2.0s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.392 total time=   2.0s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.368 total time=   2.0s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.394 total time=   2.0s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.372 total time=   1.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.388 total time=   1.8s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.405 total time=   1.8s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.377 total time=   1.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=-1.412 total time=   1.8s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.342 total time=   1.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.360 total time=   1.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.380 total time=   1.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.348 total time=   1.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=-1.403 total time=   1.1s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.183 total time=   0.6s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.053 total time=   0.7s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.229 total time=   0.7s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-6.292 total time=   0.6s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=-5.963 total time=   0.7s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.592 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.633 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.619 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.595 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.640 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.563 total time=   0.2s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.552 total time=   0.2s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.547 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.549 total time=   0.2s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.546 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.566 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.553 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.542 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.566 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.589 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.626 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.688 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.706 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.639 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.732 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.574 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.558 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.560 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.579 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.595 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.580 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.557 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.567 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.596 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.613 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.577 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.589 total time=   0.2s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.548 total time=   0.2s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.578 total time=   0.2s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.615 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.580 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.557 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.567 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.596 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.613 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.581 total time=   0.2s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.606 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.571 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.583 total time=   0.2s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.631 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.635 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.677 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.703 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.639 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.731 total time=   0.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.636 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.683 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.666 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.624 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.644 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.577 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.578 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.563 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.546 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.534 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.588 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.591 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.585 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.564 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.569 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.716 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.736 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.752 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.685 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.755 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.603 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.608 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.591 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.564 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.596 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.596 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.615 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.604 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.569 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.600 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.590 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.610 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.602 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.563 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.597 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.596 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.615 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.604 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.569 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.600 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.605 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.631 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.615 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.581 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.617 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.717 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.731 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.747 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.678 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.755 total time=   0.1s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.676 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.654 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.650 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.608 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.664 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.560 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.562 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.569 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.535 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.556 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.573 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.571 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.573 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.557 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.588 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.743 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.670 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.717 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.676 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.721 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.583 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.594 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.578 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.562 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.594 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.598 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.601 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.577 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.565 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.608 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.598 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.589 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.583 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.567 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.610 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.598 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.601 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.577 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.565 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.608 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.599 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.590 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.587 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.579 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.625 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.739 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.675 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.707 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.679 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.722 total time=   0.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.657 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.657 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.636 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.645 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.641 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.583 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.587 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.553 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.553 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.540 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.597 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.595 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.563 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.560 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.583 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.739 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.685 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.693 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.712 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.736 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.616 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.619 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.581 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.589 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.596 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.624 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.620 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.591 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.590 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.594 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.620 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.617 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.609 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.582 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.601 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.624 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.620 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.591 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.590 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.594 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.637 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.624 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.599 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.599 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.619 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.738 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.683 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.700 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.713 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.740 total time=   0.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.681 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.667 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.624 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.646 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-1.588 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.561 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.591 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.550 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.600 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-1.568 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.583 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.600 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.559 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.599 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-1.564 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.741 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.719 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.693 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.713 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-1.639 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.592 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.620 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.565 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.616 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-1.575 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.595 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.620 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.573 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.613 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-1.577 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.586 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.608 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.597 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.605 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-1.586 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.595 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.620 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.573 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.613 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-1.577 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.590 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.636 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.603 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.609 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-1.579 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.738 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.714 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.686 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.730 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-1.643 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingRegressor(estimators=[('ridge_model_log', Ridge(alpha=0.05)),\n",
              "                              ('svr_model_log',\n",
              "                               RandomizedSearchCV(cv=5,\n",
              "                                                  estimator=SVR(epsilon=0.2),\n",
              "                                                  n_jobs=1,\n",
              "                                                  param_distributions={'C': [0.5,\n",
              "                                                                             1.0,\n",
              "                                                                             1.5,\n",
              "                                                                             2.0,\n",
              "                                                                             2.5,\n",
              "                                                                             3.0,\n",
              "                                                                             3.5,\n",
              "                                                                             4.0,\n",
              "                                                                             4.5],\n",
              "                                                                       'epsilon': [0.1,\n",
              "                                                                                   0.2,\n",
              "                                                                                   0.3,\n",
              "                                                                                   0.4,\n",
              "                                                                                   0.5,\n",
              "                                                                                   0.6],\n",
              "                                                                       'gamma': [1e-07,\n",
              "                                                                                 1e-06,\n",
              "                                                                                 1e-05,\n",
              "                                                                                 0.0001,\n",
              "                                                                                 0.001,\n",
              "                                                                                 0.01,\n",
              "                                                                                 0.1],\n",
              "                                                                       'kernel': ('linear',\n",
              "                                                                                  'rbf',\n",
              "                                                                                  'poly')},\n",
              "                                                  random_state=42,\n",
              "                                                  scorin...\n",
              "                                                  param_distributions={'algorithm': ['auto',\n",
              "                                                                                     'ball_tree',\n",
              "                                                                                     'kd_tree',\n",
              "                                                                                     'brute'],\n",
              "                                                                       'leaf_size': [3,\n",
              "                                                                                     4,\n",
              "                                                                                     5,\n",
              "                                                                                     6,\n",
              "                                                                                     7,\n",
              "                                                                                     8,\n",
              "                                                                                     9,\n",
              "                                                                                     10,\n",
              "                                                                                     11,\n",
              "                                                                                     12,\n",
              "                                                                                     13,\n",
              "                                                                                     14,\n",
              "                                                                                     15,\n",
              "                                                                                     16,\n",
              "                                                                                     17,\n",
              "                                                                                     18,\n",
              "                                                                                     19,\n",
              "                                                                                     20,\n",
              "                                                                                     21,\n",
              "                                                                                     22,\n",
              "                                                                                     23,\n",
              "                                                                                     24,\n",
              "                                                                                     25,\n",
              "                                                                                     26,\n",
              "                                                                                     27,\n",
              "                                                                                     28,\n",
              "                                                                                     29],\n",
              "                                                                       'n_neighbors': [3,\n",
              "                                                                                       4,\n",
              "                                                                                       5,\n",
              "                                                                                       6,\n",
              "                                                                                       7,\n",
              "                                                                                       8,\n",
              "                                                                                       9,\n",
              "                                                                                       10,\n",
              "                                                                                       11,\n",
              "                                                                                       12,\n",
              "                                                                                       13,\n",
              "                                                                                       14,\n",
              "                                                                                       15,\n",
              "                                                                                       16,\n",
              "                                                                                       17,\n",
              "                                                                                       18,\n",
              "                                                                                       19]},\n",
              "                                                  random_state=42,\n",
              "                                                  scoring='neg_mean_squared_error',\n",
              "                                                  verbose=3))],\n",
              "                  final_estimator=RandomForestRegressor(n_estimators=15,\n",
              "                                                        random_state=42))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = final_model.predict(x_test)"
      ],
      "metadata": {
        "id": "dQIPlcI1tXRr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (6,6))\n",
        "sns.distplot(y_test-prediction)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "_m4PcadeuNii",
        "outputId": "21df7ee7-a82d-4e57-81e9-8af271609e9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlHWqU_MuN1I",
        "outputId": "a614900b-7901-4d26-e4e7-b6d5a3a6cd43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.9890854358613185\n",
            "MSE: 1.5310609562059991\n",
            "RMSE: 1.2373604794909199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('StackedModelLog.pkl', 'wb')\n",
        "pickle.dump(final_model, file)"
      ],
      "metadata": {
        "id": "7jcm2v0iFrJp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Log "
      ],
      "metadata": {
        "id": "S4fpfM8RCzoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = data['x_train']\n",
        "x_test = data['x_test']\n",
        "y_train = data['y_train']\n",
        "y_test = data['y_test']"
      ],
      "metadata": {
        "id": "QEVvzC-1CzoQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " rf_model = pickle.load(open('RandomForestRegressor.pkl', 'rb'))\n",
        "# ridge_model = pickle.load(open('RidgeRegression.pkl', 'rb'))\n",
        "svr_model = pickle.load(open('SupportVectorRegressor.pkl', 'rb'))\n",
        "# xgb_model = pickle.load(open('XGBRegressor.pkl', 'rb'))\n",
        "dtr_model = pickle.load(open('DecisionTree.pkl', 'rb'))\n",
        "knn_model = pickle.load(open('KNeighborsRegressor.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "glTQkr5oCzoR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "    ('rf_model', rf_model), \n",
        "    # ('ridge_model', ridge_model), \n",
        "    ('svr_model', svr_model),\n",
        "    # ('xgb_model', xgb_model),\n",
        "    ('knn_model', knn_model)\n",
        "]"
      ],
      "metadata": {
        "id": "VF_teiygCzoU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = StackingRegressor(\n",
        "    estimators = estimators, \n",
        "    final_estimator = RandomForestRegressor(n_estimators = 15, random_state = 42)\n",
        ")"
      ],
      "metadata": {
        "id": "8yzMBX62CzoV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1826ae1-3991-486e-d4da-e2ce485424e9",
        "id": "QnNDWMCLCzoW"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2638945843754650.500 total time=   7.7s\n",
            "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2712896011699933.500 total time=   5.9s\n",
            "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2500468769184660.500 total time=   3.9s\n",
            "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2560001517710152.000 total time=   3.9s\n",
            "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2784867297543220.000 total time=   4.5s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2631497144255035.000 total time=   5.8s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2730980144482758.000 total time=   5.8s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2497022574136210.500 total time=   5.8s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2557796265522093.500 total time=   5.8s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2817463546309559.000 total time=   5.8s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2657823710424356.500 total time=   2.2s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2771264270998036.000 total time=   2.2s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2544417036164444.000 total time=   2.2s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2576262458197270.000 total time=   2.2s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2789628178929628.000 total time=   2.4s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2666199344481054.000 total time=   3.8s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2791470034482932.500 total time=   3.8s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2606044754843612.000 total time=   3.8s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2552677937818957.000 total time=   3.8s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2849097027512341.000 total time=   3.8s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2674620766527501.000 total time=   6.1s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2776161324700008.500 total time=   6.0s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2587329801236783.500 total time=   6.0s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2573089220885350.000 total time=   7.6s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2830236798793938.500 total time=   6.0s\n",
            "[CV 1/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2945937027591798.000 total time=   8.2s\n",
            "[CV 2/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3048742171720610.000 total time=   8.1s\n",
            "[CV 3/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2813308395954318.500 total time=   8.0s\n",
            "[CV 4/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2853874621544269.000 total time=   8.1s\n",
            "[CV 5/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3183483583729025.000 total time=   8.9s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2799249993449435.000 total time=   3.5s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2803313853602522.000 total time=   3.5s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2630115528582653.000 total time=   3.5s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2710531141423806.500 total time=   3.5s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2872168782236027.000 total time=   3.5s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2634060457008450.500 total time=   1.6s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2713073089229763.500 total time=   1.6s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2498168499134408.000 total time=   1.6s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2556940501695154.500 total time=   1.6s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2830714724110634.000 total time=   1.6s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2810356398090072.000 total time=   2.2s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2799511575989111.000 total time=   2.2s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2622775962379963.500 total time=   2.2s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2707256787113229.500 total time=   2.2s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2866913794271406.500 total time=   2.2s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2678407567206020.500 total time=   7.8s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2780741305454985.500 total time=   6.9s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2588187484943756.000 total time=   6.9s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2581044266334387.000 total time=   6.9s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2873807497955106.500 total time=   7.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3706621705411730.500 total time=   5.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3702840301315333.000 total time=   6.0s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3489651862410509.000 total time=   5.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3574801019277624.000 total time=   6.0s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3701054898485142.000 total time=   5.9s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3706614339584159.000 total time=   3.7s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3702829426623110.000 total time=   3.6s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3489641429064335.500 total time=   3.7s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3574788862790255.500 total time=   3.7s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3701045371165753.000 total time=   3.6s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3706622788362211.000 total time=   3.6s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3702841594214894.000 total time=   3.7s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3489653137246273.000 total time=   3.6s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3574802553622380.500 total time=   3.7s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3701056127876887.500 total time=   3.6s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3706061529578147.000 total time=   3.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3702163483787912.500 total time=   3.4s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3488993557188968.500 total time=   3.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3573998145420530.000 total time=   3.4s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3700412976720097.000 total time=   3.4s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3706061529578147.000 total time=   3.4s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3702163497872783.000 total time=   3.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3488993548735244.500 total time=   3.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3573998145420530.000 total time=   3.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3700412963414345.000 total time=   3.3s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3706621716726596.500 total time=   5.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3702840314280511.500 total time=   6.0s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3489651892618664.500 total time=   6.0s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3574801031660700.500 total time=   5.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3701054910617490.500 total time=   5.9s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3706622797673458.000 total time=   5.7s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3702841610103271.000 total time=   6.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3489653152428077.000 total time=   5.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3574802571384722.500 total time=   6.1s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3701056141220315.500 total time=   5.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3706435687882193.000 total time=   3.3s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3702615530935573.500 total time=   3.3s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3489433261628045.000 total time=   3.4s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3574534378012282.500 total time=   3.3s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3700841735751408.500 total time=   3.4s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3706560439033815.500 total time=   3.3s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3702766244484881.000 total time=   3.3s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3489579875462384.000 total time=   3.3s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3574713181091487.000 total time=   3.3s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3700984699342059.000 total time=   3.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3706622707999277.000 total time=   5.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3702841485476177.500 total time=   5.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3489653030765486.000 total time=   5.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3574802433012888.500 total time=   5.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3701056028654103.500 total time=   5.9s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3214040406398160.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3116192237058037.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-2921400040534203.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3046568907205144.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3316535462804358.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3073413995734689.000 total time=   0.4s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2982305078582899.000 total time=   0.4s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2826898110284954.500 total time=   0.4s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2872239768832972.000 total time=   0.4s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3149234264426051.500 total time=   0.5s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3098355097443245.500 total time=   0.2s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3024421945017688.000 total time=   0.2s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2833524761906292.500 total time=   0.2s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2917849006706734.000 total time=   0.2s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3177053455862824.000 total time=   0.2s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3294750216551167.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3206897897978456.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3014804400605027.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3137508718777379.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3401852498250561.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3098940350783047.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3008928464567785.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2869761481896449.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2945087312568067.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3240425966792965.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3138843879105475.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3027160049566427.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2865772065918761.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2962384266239677.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3268577728883251.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3155707939757630.500 total time=   0.4s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3017292992356373.500 total time=   0.4s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2868160125746858.000 total time=   0.5s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2942201866375224.000 total time=   0.4s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3263379647272115.000 total time=   0.4s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3138843879105475.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3027160049566427.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2865772065918761.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2962384266239677.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3268577728883251.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3182201379918877.500 total time=   0.4s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3020057444013343.000 total time=   0.4s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2890009097344128.000 total time=   0.4s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2971342827306780.000 total time=   0.4s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3280454687525709.000 total time=   0.5s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3338042954303411.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3214480172827648.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3015901623536804.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3141829738978455.500 total time=   0.1s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3396794331164795.500 total time=   0.1s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2720519043778186.000 total time=   3.3s\n",
            "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2530506967364837.500 total time=   3.3s\n",
            "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2539090545130979.500 total time=   3.4s\n",
            "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2757370946659297.000 total time=   3.3s\n",
            "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2737779177912184.000 total time=   3.3s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2711035552511876.000 total time=   4.9s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2567698721969532.000 total time=   4.8s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2557947282097403.500 total time=   4.8s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2748753200886436.500 total time=   4.8s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2779065858659335.000 total time=   4.8s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2755621837959998.500 total time=   1.8s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2574903756429193.500 total time=   1.7s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2523193242994438.000 total time=   1.8s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2753479772472173.500 total time=   1.8s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2766087972169319.500 total time=   1.8s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2766443091803115.500 total time=   3.1s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2662977999410106.000 total time=   3.1s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2611962007577782.000 total time=   3.1s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2751663355333030.000 total time=   3.1s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2824925611286831.500 total time=   3.1s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2760875865916753.000 total time=   4.9s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2622247796056744.500 total time=   5.7s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2578741226675674.500 total time=   5.0s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2743799547374128.500 total time=   5.0s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2788032563764232.500 total time=   4.9s\n",
            "[CV 1/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3005837817532555.000 total time=   6.7s\n",
            "[CV 2/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2964474459711743.000 total time=   6.7s\n",
            "[CV 3/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3000117612224215.000 total time=   6.6s\n",
            "[CV 4/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3036811381197547.500 total time=   6.7s\n",
            "[CV 5/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3167506413002581.500 total time=   6.7s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2839934390892199.500 total time=   3.0s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2618805586923516.500 total time=   3.0s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2674120181845494.000 total time=   3.0s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2901049915450209.000 total time=   3.0s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2796069023415148.500 total time=   3.0s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2710123506796693.500 total time=   1.3s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2554630434083521.500 total time=   1.3s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2549109924515762.500 total time=   1.3s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2757457990002233.000 total time=   1.3s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2781233643487516.500 total time=   1.3s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2828732192935802.000 total time=   1.9s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2606125727142751.000 total time=   1.9s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2673058137063243.500 total time=   1.9s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2907624396976912.500 total time=   1.9s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2795816227000400.500 total time=   1.9s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2762580573011243.000 total time=   5.6s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2655997748147404.000 total time=   5.6s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2597254283064740.500 total time=   5.6s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2795981700854256.500 total time=   5.7s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2809779215480097.500 total time=   5.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2669338573541662.500 total time=   3.4s\n",
            "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2490280305766825.500 total time=   3.3s\n",
            "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2524400949398916.000 total time=   3.3s\n",
            "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2726301017601997.000 total time=   3.3s\n",
            "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2738728376454757.500 total time=   3.3s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2671568474240402.500 total time=   4.8s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2536465329083180.000 total time=   4.8s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2538218776472276.000 total time=   4.8s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2731175103651881.000 total time=   4.8s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2789918413931262.500 total time=   4.8s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2681264499729769.000 total time=   1.8s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2513094429181612.500 total time=   1.7s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2537542640427607.000 total time=   1.8s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2739955395068963.500 total time=   1.7s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2736030488701065.500 total time=   1.8s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2704502177715275.000 total time=   3.1s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2602240662049617.500 total time=   3.1s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2591276559135433.500 total time=   3.2s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2758591176089448.500 total time=   3.8s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2829875683303167.500 total time=   3.1s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2692852117902711.000 total time=   4.9s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2581500828503703.000 total time=   4.9s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2561961517027659.000 total time=   4.9s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2746847292178760.500 total time=   4.9s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2779073793636015.500 total time=   4.8s\n",
            "[CV 1/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3014271490307423.000 total time=   6.6s\n",
            "[CV 2/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2893882385201380.500 total time=   6.6s\n",
            "[CV 3/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2935133464328343.500 total time=   6.6s\n",
            "[CV 4/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3071557937869536.500 total time=   6.7s\n",
            "[CV 5/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3170389775498414.500 total time=   6.6s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2846665605522999.000 total time=   3.0s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2571833659446809.500 total time=   3.0s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2657650155179215.000 total time=   3.0s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2878694621640706.500 total time=   3.0s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2777549424312436.500 total time=   3.0s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2681220264806643.500 total time=   1.3s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2555162230024634.000 total time=   1.3s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2538161326194078.500 total time=   1.3s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2726827843612244.000 total time=   1.3s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2783495926520289.000 total time=   1.3s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2851798379582333.000 total time=   1.9s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2570129222323114.000 total time=   1.9s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2652546228625581.500 total time=   2.0s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2879711234797456.500 total time=   1.9s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2769534224937916.000 total time=   1.9s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2698443739798828.500 total time=   6.9s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2592700235843792.000 total time=   6.8s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2596105313220115.000 total time=   5.5s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2791729164441211.500 total time=   5.6s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2821151497813396.500 total time=   5.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2715923413923917.000 total time=   3.3s\n",
            "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2577128820639953.000 total time=   3.3s\n",
            "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2729142502916581.000 total time=   3.3s\n",
            "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2739522646311872.000 total time=   3.3s\n",
            "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2701578344004434.000 total time=   3.3s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2708770738936043.500 total time=   4.8s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2594937046941570.000 total time=   4.8s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2770594968288615.500 total time=   4.8s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2728342435104325.500 total time=   4.9s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2736291096823410.500 total time=   4.9s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2712039923940340.000 total time=   1.9s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2580830598442913.000 total time=   2.5s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2770571974156765.500 total time=   1.8s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2744237882878383.000 total time=   1.7s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2736098384556046.500 total time=   1.7s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2777902305684576.500 total time=   3.1s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2634605635041588.500 total time=   3.1s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2861783240470012.000 total time=   3.1s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2731218511567062.000 total time=   3.1s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2785321260467581.500 total time=   3.1s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2755699542678642.500 total time=   4.9s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2605622254053907.000 total time=   4.9s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2829976737865354.500 total time=   4.8s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2722153092660116.000 total time=   4.8s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2748515100946078.000 total time=   4.9s\n",
            "[CV 1/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2937545964447062.500 total time=   6.7s\n",
            "[CV 2/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3017900814152354.500 total time=   6.6s\n",
            "[CV 3/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3092809937738347.500 total time=   6.6s\n",
            "[CV 4/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3114161652933978.000 total time=   6.6s\n",
            "[CV 5/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3146666732002431.500 total time=   6.6s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2882541689261913.500 total time=   3.0s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2678018397636494.000 total time=   3.0s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2786502782131691.500 total time=   3.1s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2893130026838913.500 total time=   3.0s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2785098711674387.000 total time=   3.0s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2704400041399742.000 total time=   1.3s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2605472629334714.000 total time=   1.3s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2782947360571769.500 total time=   1.3s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2731786979404427.500 total time=   1.3s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2727931368253324.000 total time=   1.3s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2887664193034731.500 total time=   1.9s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2673972584583607.000 total time=   1.9s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2779916380260177.500 total time=   1.9s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2890171958644137.000 total time=   1.9s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2787725367485518.000 total time=   1.9s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2792082705228970.500 total time=   5.6s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2640827174145604.500 total time=   5.6s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2848825422222085.500 total time=   5.5s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2759950618684096.500 total time=   5.5s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2787592618367462.000 total time=   5.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2708958421663461.000 total time=   3.3s\n",
            "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2558736602044476.000 total time=   3.3s\n",
            "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2728607985773411.500 total time=   3.3s\n",
            "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2660599434584960.500 total time=   3.3s\n",
            "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2740839423749799.000 total time=   3.3s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2707502054117081.000 total time=   4.9s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2569399143236620.500 total time=   4.8s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2778088506191967.500 total time=   5.7s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2684176791778272.000 total time=   4.9s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2799595830576447.000 total time=   4.8s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2722170377229767.000 total time=   1.7s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2607081562093060.500 total time=   1.8s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2810852248961671.000 total time=   1.7s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2643179420758176.500 total time=   1.8s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2750127637633919.500 total time=   1.7s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2737310673087625.500 total time=   3.1s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2598951093449877.500 total time=   3.1s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2907745446916555.000 total time=   3.1s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2723336850413483.000 total time=   3.1s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2845286896547833.000 total time=   3.1s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2734662062696138.000 total time=   4.9s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2594171781144757.500 total time=   4.9s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2864683172665718.500 total time=   4.8s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2658839605387186.500 total time=   4.8s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2797408419421229.000 total time=   4.8s\n",
            "[CV 1/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3006859525649681.000 total time=   6.6s\n",
            "[CV 2/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2910343819976360.500 total time=   6.7s\n",
            "[CV 3/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3194107723679288.500 total time=   6.6s\n",
            "[CV 4/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3108816337003218.500 total time=   6.7s\n",
            "[CV 5/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3211696872964629.500 total time=   6.8s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2876094733704686.500 total time=   3.2s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2681467850799493.500 total time=   3.0s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2777271249029616.000 total time=   3.0s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2794498965308011.500 total time=   3.0s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2782888491047529.000 total time=   3.0s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2710470895099035.500 total time=   1.3s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2568301395265165.500 total time=   1.3s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2785437232448223.500 total time=   1.3s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2681635943586077.000 total time=   1.3s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2790202072629593.000 total time=   1.3s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2863602458257896.000 total time=   1.9s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2682538499302996.500 total time=   1.9s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2770937907565160.500 total time=   1.9s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2801263592236664.000 total time=   1.9s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2783360432194164.500 total time=   1.9s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2746646536009955.000 total time=   5.5s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2599015124649784.500 total time=   5.6s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2907087072163487.000 total time=   5.5s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2763643297040807.000 total time=   5.6s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2863978510255815.500 total time=   5.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2701957483980281.000 total time=   3.3s\n",
            "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2563484697853583.000 total time=   3.3s\n",
            "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2713558180094930.000 total time=   3.3s\n",
            "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2427074875851113.000 total time=   3.3s\n",
            "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900;, score=-2651938209468018.500 total time=   3.6s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2690892803024196.500 total time=   5.5s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2556936989443403.000 total time=   4.9s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2755213359910166.000 total time=   4.8s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2420738156853639.000 total time=   4.8s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100;, score=-2635231769025340.500 total time=   4.8s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2735877965931336.000 total time=   1.8s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2584346164497330.500 total time=   1.8s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2774099955901477.500 total time=   1.7s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2455466031353519.000 total time=   1.8s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300;, score=-2687233469959650.000 total time=   1.7s\n",
            "[CV 1/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2734766634226192.500 total time=   3.1s\n",
            "[CV 2/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2598818342005493.000 total time=   3.1s\n",
            "[CV 3/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2868261900359160.500 total time=   3.1s\n",
            "[CV 4/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2530241359611938.500 total time=   3.1s\n",
            "[CV 5/5] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400;, score=-2688854356038299.500 total time=   3.1s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2745073108733428.000 total time=   5.0s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2588541258195057.000 total time=   5.2s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2843420465681463.000 total time=   4.8s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2490659018357293.500 total time=   4.9s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700;, score=-2678723454437530.000 total time=   4.9s\n",
            "[CV 1/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2956021743038427.000 total time=   6.7s\n",
            "[CV 2/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2869448042577613.500 total time=   6.7s\n",
            "[CV 3/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-3181734353939320.500 total time=   6.7s\n",
            "[CV 4/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2766072677130480.000 total time=   6.7s\n",
            "[CV 5/5] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=-2892471185676059.500 total time=   6.7s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2876950394185323.500 total time=   3.0s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2671722004190331.000 total time=   3.0s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2770946476092505.000 total time=   3.0s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2588451426127869.500 total time=   3.0s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100;, score=-2787175745845981.000 total time=   3.0s\n",
            "[CV 1/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2691666082310761.000 total time=   1.3s\n",
            "[CV 2/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2556317817787166.500 total time=   1.3s\n",
            "[CV 3/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2755749473112340.000 total time=   1.3s\n",
            "[CV 4/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2407596410015715.500 total time=   1.3s\n",
            "[CV 5/5] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=-2640515248310417.000 total time=   1.3s\n",
            "[CV 1/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2879575790538644.000 total time=   1.9s\n",
            "[CV 2/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2678147588542739.000 total time=   1.9s\n",
            "[CV 3/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2767693545751413.000 total time=   1.9s\n",
            "[CV 4/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2585764876044155.000 total time=   1.9s\n",
            "[CV 5/5] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700;, score=-2785226066858295.500 total time=   1.9s\n",
            "[CV 1/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2747073033874244.000 total time=   5.7s\n",
            "[CV 2/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2595701395664280.500 total time=   5.6s\n",
            "[CV 3/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2855240574997064.000 total time=   5.6s\n",
            "[CV 4/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2515659919507505.000 total time=   5.6s\n",
            "[CV 5/5] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700;, score=-2706428750848411.500 total time=   5.6s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3768255365210472.500 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3346277597425551.500 total time=   4.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3651433119187832.500 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3759802577617020.500 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3559536594152002.000 total time=   3.9s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3768246155281385.500 total time=   2.3s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3346273043614004.000 total time=   2.3s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3651427691768871.000 total time=   2.3s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3759794390819710.000 total time=   2.3s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3559531592223798.500 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3768256604810746.500 total time=   2.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3346278353185869.500 total time=   2.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3651433842682023.000 total time=   2.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3759803707790491.500 total time=   2.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3559537333166099.500 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3767607110361710.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3345885095262328.500 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3651044220100150.500 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3759220292620586.000 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3559146106391108.500 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3767607110361710.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3345885095262328.500 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3651044220100150.500 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3759220292620586.000 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3559146106391108.500 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3768255390559366.000 total time=   3.8s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3346277615669612.500 total time=   3.8s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3651433130858756.500 total time=   3.9s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3759802574325570.500 total time=   3.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3559536589734650.000 total time=   3.9s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3768256619772517.500 total time=   3.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3346278361117589.000 total time=   3.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3651433851828789.000 total time=   3.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3759803720356541.500 total time=   3.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3559537341322289.000 total time=   3.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3768040095633903.500 total time=   2.1s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3346147266271294.000 total time=   2.1s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3651303974901306.000 total time=   2.1s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3759609223579489.000 total time=   2.1s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3559406924863869.500 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3768184456866456.000 total time=   2.1s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3346234671626852.000 total time=   2.1s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3651390573136115.500 total time=   2.1s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3759738899155628.000 total time=   2.1s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3559493881624891.000 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3768256511167782.000 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3346278303946043.000 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3651433792492257.500 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3759803616915683.000 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3559537280204180.000 total time=   3.9s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3797018933940627.000 total time=   3.8s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3305688837675950.500 total time=   3.8s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3651432985717899.000 total time=   3.8s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3759802040088228.000 total time=   3.8s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3559536409051909.500 total time=   3.9s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3797013987978866.500 total time=   2.3s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3305682941211246.000 total time=   2.3s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3651426420992257.500 total time=   2.3s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3759781137999052.000 total time=   2.3s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3559528766082583.000 total time=   3.4s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3797019699061070.500 total time=   2.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3305689345469214.500 total time=   2.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3651433840943783.000 total time=   2.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3759803696877228.000 total time=   2.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3559537329756749.000 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796611923002396.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3305438306696784.000 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3650977181047623.500 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3758937063506040.500 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3559062790464862.500 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3796611923002396.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3305438306696784.000 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3650977167404945.500 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3758937063506040.500 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3559062790464862.500 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3797018942094534.500 total time=   3.8s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3305688868370166.000 total time=   3.8s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3651433007811587.500 total time=   3.8s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3759802109133979.000 total time=   3.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3559536427376698.500 total time=   3.9s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3797019706905481.500 total time=   3.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3305689350475652.500 total time=   3.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3651433851744207.500 total time=   3.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3759803720103783.000 total time=   3.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3559537341174485.000 total time=   3.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3796883775429720.000 total time=   2.1s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3305605642208187.000 total time=   2.1s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3651281635529081.500 total time=   2.1s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3759514774681727.000 total time=   2.1s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3559379146878537.000 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796974409712739.500 total time=   2.1s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3305661432731558.500 total time=   2.1s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3651383137536254.000 total time=   2.1s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3759707411834939.000 total time=   2.1s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3559484621628679.000 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3797019648917260.500 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3305689300221258.000 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3651433775669431.500 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3759803566424985.000 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3559537257955277.500 total time=   3.9s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3797018866749651.500 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3467904658410311.000 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3729893303901702.500 total time=   3.8s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3737895816522663.000 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3559536347445460.500 total time=   3.9s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3797014087530119.500 total time=   2.3s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3467910192468995.500 total time=   2.3s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3729888659435161.500 total time=   2.3s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3737897203746253.000 total time=   2.3s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3559528573798756.500 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3797019698461142.000 total time=   2.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3467904207036578.000 total time=   2.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3729894029834008.000 total time=   2.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3737895548531153.500 total time=   2.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3559537328221758.500 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796583814010434.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3468141310271468.500 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3729514173185914.500 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3738043952693643.500 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3559023218809088.500 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3796583814010434.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3468141297843832.000 total time=   3.2s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3729514173185914.500 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3738043952693643.500 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3559023231844391.000 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3797018878619118.500 total time=   3.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3467904661150365.500 total time=   3.9s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3729893306944173.000 total time=   3.8s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3737895830092702.500 total time=   3.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3559536355730139.000 total time=   3.9s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3797019706872057.500 total time=   3.9s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3467904201564314.500 total time=   3.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3729894039080787.000 total time=   3.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3737895543575167.500 total time=   3.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3559537341133611.000 total time=   3.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3796874402952434.000 total time=   2.1s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3467983205772200.500 total time=   2.1s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3729767419299856.000 total time=   2.1s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3737944978313970.500 total time=   2.1s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3559365942129978.000 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796971285241055.500 total time=   2.1s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3467930534484689.500 total time=   2.1s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3729851847081740.000 total time=   2.1s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3737912005049795.000 total time=   2.1s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3559480203656865.000 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3797019647102966.000 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3467904243997793.500 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3729893983649653.000 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3737895567454329.000 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3559537248482527.000 total time=   3.9s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3797018815009418.500 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3467904676671168.500 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3583288049999968.500 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3799946964501844.000 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3559536220905458.000 total time=   3.9s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3797012592228525.500 total time=   2.3s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3467910868496575.500 total time=   2.3s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3583281039871495.500 total time=   2.3s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3799938754003194.500 total time=   2.3s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3559527727785162.500 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3797019698020691.000 total time=   2.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3467904206832308.000 total time=   2.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3583289012235638.500 total time=   2.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3799948057635875.500 total time=   2.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3559537327099402.000 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796555108987607.500 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3468160330035648.000 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3582787676425097.000 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3799365781375149.500 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3558956889304717.000 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3796555108987607.500 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3468160330035648.000 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3582787676425097.000 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3799365781375149.500 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3558956889304717.000 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3797018823470456.000 total time=   3.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3467904681248796.500 total time=   3.9s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3583288073992073.000 total time=   3.8s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3799946985812843.500 total time=   4.5s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3559536224650107.500 total time=   4.4s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3797019706873079.000 total time=   3.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3467904201538656.000 total time=   3.8s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3583289023813157.500 total time=   3.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3799948070183263.000 total time=   3.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3559537341090799.000 total time=   3.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3796864832521947.000 total time=   2.1s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3467989533658293.500 total time=   2.1s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3583121897319087.500 total time=   2.1s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3799753959367520.500 total time=   2.1s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3559343835414453.500 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796968094865388.500 total time=   2.1s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3467932628333238.000 total time=   2.1s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3583233314732065.500 total time=   2.1s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3799883379072713.500 total time=   2.1s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3559472849909831.500 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3797019630187350.500 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3467904240416763.500 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3583288930153635.000 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3799947968568402.500 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3559537239127898.500 total time=   3.9s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3797019006113134.000 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3484651867587165.000 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3581281991067945.500 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3589991492898610.500 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.001, kernel=rbf;, score=-3613702009170966.000 total time=   3.9s\n",
            "[CV 1/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3797014551863682.000 total time=   2.3s\n",
            "[CV 2/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3484650070462380.000 total time=   2.3s\n",
            "[CV 3/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3581276136005772.000 total time=   2.3s\n",
            "[CV 4/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3589986254769479.500 total time=   2.3s\n",
            "[CV 5/5] END C=3.5, epsilon=0.5, gamma=0.1, kernel=poly;, score=-3613685385466958.500 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3797019699339630.500 total time=   2.3s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3484651794751568.500 total time=   2.3s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3581282841997280.500 total time=   2.3s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3589992259250693.500 total time=   2.3s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.01, kernel=poly;, score=-3613703614881260.000 total time=   2.3s\n",
            "[CV 1/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796643865687441.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3484686731393459.000 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3580826772802759.000 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3589589440131908.000 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3612856235811911.500 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3796643851948008.000 total time=   2.1s\n",
            "[CV 2/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3484686731393459.000 total time=   2.1s\n",
            "[CV 3/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3580826768966027.500 total time=   2.1s\n",
            "[CV 4/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3589589440131908.000 total time=   2.1s\n",
            "[CV 5/5] END C=4.5, epsilon=0.2, gamma=0.01, kernel=linear;, score=-3612856235811911.500 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3797019012003761.500 total time=   3.9s\n",
            "[CV 2/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3484651882657850.500 total time=   3.9s\n",
            "[CV 3/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3581282007158798.500 total time=   3.8s\n",
            "[CV 4/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3589991511665778.500 total time=   3.9s\n",
            "[CV 5/5] END C=0.5, epsilon=0.6, gamma=0.01, kernel=rbf;, score=-3613702044554133.000 total time=   3.9s\n",
            "[CV 1/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3797019706929080.000 total time=   3.8s\n",
            "[CV 2/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3484651797002326.500 total time=   3.9s\n",
            "[CV 3/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3581282851135094.500 total time=   3.8s\n",
            "[CV 4/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3589992267861551.500 total time=   3.8s\n",
            "[CV 5/5] END C=2.0, epsilon=0.5, gamma=1e-06, kernel=rbf;, score=-3613703638719154.000 total time=   3.8s\n",
            "[CV 1/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3796894434848189.000 total time=   2.1s\n",
            "[CV 2/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3484663426401940.000 total time=   3.2s\n",
            "[CV 3/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3581130821035103.000 total time=   2.1s\n",
            "[CV 4/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3589857991387104.500 total time=   2.1s\n",
            "[CV 5/5] END C=1.5, epsilon=0.4, gamma=0.01, kernel=linear;, score=-3613421107833333.000 total time=   2.1s\n",
            "[CV 1/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3796977979778948.000 total time=   2.1s\n",
            "[CV 2/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3484655671739709.500 total time=   2.1s\n",
            "[CV 3/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3581232192010986.000 total time=   2.1s\n",
            "[CV 4/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3589947522897842.000 total time=   2.1s\n",
            "[CV 5/5] END C=0.5, epsilon=0.5, gamma=1e-06, kernel=linear;, score=-3613609467765954.000 total time=   2.1s\n",
            "[CV 1/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3797019650464115.000 total time=   3.9s\n",
            "[CV 2/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3484651803952800.000 total time=   3.9s\n",
            "[CV 3/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3581282787270643.500 total time=   3.9s\n",
            "[CV 4/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3589992210335181.000 total time=   3.9s\n",
            "[CV 5/5] END C=4.5, epsilon=0.6, gamma=0.0001, kernel=rbf;, score=-3613703475336857.000 total time=   3.9s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3052765532682821.000 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3012434791251517.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-2985984751978973.000 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3164747325976316.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3326221931194026.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2979834383174231.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2809077372522805.500 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2836448458701199.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3060533123177565.000 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3075065187692185.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2981092360172835.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2837268369760059.500 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2856399814817803.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3061195993454266.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3136784740294795.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3130223213007291.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3082015285158249.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3105718510897868.000 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3273757634024691.000 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3431432798103254.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3000252854820318.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2827365317184239.000 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2893546729389394.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3058301470775245.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3167549693181586.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3005234249638250.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2842534368172278.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2906118195943321.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3101019489584175.000 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3188076746183502.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2967169769556927.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2876422511070146.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2864380279312570.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3092384098948934.000 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3221477036617284.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3005234249638250.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2842534368172278.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2906118195943321.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3101019489584175.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3188076746183502.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3000484142421913.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2951872307087334.500 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2899367844199193.500 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3109094594578848.000 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3252733578940987.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3133317318600112.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3063528785802469.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3091198588267115.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3264939883194163.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3401447656015713.000 total time=   0.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3199233076185516.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3032604575974026.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3036091055518908.000 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3180015623141849.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3265906806018232.000 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3135777232505186.500 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2857296636861502.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2900313070449012.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3032516766557734.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3092285349284269.500 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3164556949036097.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2841136922365004.500 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2952525599086194.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3074424801470325.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3160743012566161.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3300302974438586.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3120717339739618.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3141166715930415.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3329339417551066.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3430249699061728.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3167501766438308.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2898047007835007.500 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2960957877962359.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3084932243562345.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3212968840813553.000 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3152619875091980.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2865808860535914.500 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2963478500192480.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3095866650892256.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3230188555528619.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3120059852662367.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2926987084103815.500 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2967137293753086.500 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3096559933018519.000 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3208595722951740.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3152619875091980.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2865808860535914.500 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2963478500192480.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3095866650892256.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3230188555528619.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3124093613269355.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2964816749840656.500 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2976959326793310.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3116937350792562.000 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3239769548563135.500 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3314269659452608.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3117132953443322.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3141218325647587.000 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3327811514260381.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3437667251890011.000 total time=   0.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3228550070811633.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3026454671726333.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3192409550691724.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3217776919256052.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3286469477928949.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3149959784177749.500 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2898382126254276.500 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3003497409546251.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3022259329182443.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3111448552376126.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3133951553263398.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2911177673921662.500 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3025404850257008.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3050529409819098.500 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3160761415075143.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3268793164269209.000 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3121159401295174.000 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3331750280148148.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3349320167259259.000 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3382584526386083.000 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3148213101370612.000 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2915568440620623.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3046869733105156.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3059873248073944.000 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3208506283273042.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3164134596207515.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2941299426895062.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3058795748910774.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3105962681542087.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3223070000965769.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3156515971008412.500 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2922433676687991.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3053189253208753.500 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3105478346326599.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3205098827886644.500 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3164134596207515.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2941299426895062.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3058795748910774.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3105962681542087.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3223070000965769.000 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3141616092073284.500 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2939988272557537.500 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3069451735868285.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3143538013947430.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3245314006460350.500 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3274450895131800.000 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3115557416987654.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3318711713268238.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3357862385916947.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3376246100208754.500 total time=   0.0s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3275085453501894.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-2999635687697840.000 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3181609179729265.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3176695296130236.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3265587662620536.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3174159850551246.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2904997699080967.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3011781843452790.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3014133398573392.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3102176155860023.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3194712634718097.000 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2942829613277747.500 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3005196396266744.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3043671494422861.500 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3148854284173091.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3378610829332585.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3063828110895623.000 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3330672451930415.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3282660965898990.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3417291460356902.000 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3228236830163203.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2993749493543330.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3033734152488151.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3091127323353368.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3161914033899602.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3215195986874929.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3004503653896184.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3059928164641975.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3084056224975309.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3188901859698092.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3220054385249018.500 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2995705331754208.500 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3104024661625140.500 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3094412674888327.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3190208015795735.500 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3215195986874929.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3004503653896184.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3059928164641975.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3084056224975309.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3188901859698092.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3239353765563657.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3001676498768203.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3092903578526000.500 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3133939075541422.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3233891373566945.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3376630912370163.000 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3070200572076318.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3345532515975308.000 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3280769338469136.000 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3403695535481481.500 total time=   0.1s\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3254857270716632.000 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3022697459845250.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3165851225072722.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-2891834296016857.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=7;, score=-3079963546529925.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3115703089334099.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2927036810364904.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3010728880314680.500 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-2854945673289411.000 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=7, n_neighbors=17;, score=-3000409027448067.500 total time=   0.3s\n",
            "[CV 1/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3094825421790612.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2925909072538804.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-3034561015933829.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2847440666970162.000 total time=   0.1s\n",
            "[CV 5/5] END algorithm=ball_tree, leaf_size=26, n_neighbors=13;, score=-2984706323715790.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3332527485873247.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3183772580702187.500 total time=   0.0s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3296417358565656.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-2955106020484849.000 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=-3175316225937149.500 total time=   0.0s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3081057599794663.000 total time=   0.0s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2959496215439203.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3034792394162933.000 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-2870470377124783.500 total time=   0.0s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=11;, score=-3037375251524890.500 total time=   0.1s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3113645144303420.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2961086231986540.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3068470091417508.500 total time=   0.1s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-2872052979285634.500 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=10;, score=-3037041591401796.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3121151096909141.500 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2958802602848009.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3117537185142537.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-2827925856081930.500 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=23, n_neighbors=10;, score=-3084790458721661.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3113645144303420.500 total time=   0.1s\n",
            "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2961086231986540.000 total time=   0.1s\n",
            "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3068470091417508.500 total time=   0.0s\n",
            "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-2872052979285634.500 total time=   0.1s\n",
            "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=10;, score=-3037041591401796.000 total time=   0.1s\n",
            "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3124139385223268.000 total time=   0.3s\n",
            "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3005430294977254.000 total time=   0.3s\n",
            "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3125068440012609.000 total time=   0.3s\n",
            "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-2824860718125009.000 total time=   0.3s\n",
            "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=9;, score=-3068358046069058.000 total time=   0.3s\n",
            "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3348337379221536.500 total time=   0.0s\n",
            "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3176996350095345.000 total time=   0.0s\n",
            "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3299494761212121.000 total time=   0.0s\n",
            "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3021318145288440.000 total time=   0.0s\n",
            "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=5;, score=-3171207490906846.500 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingRegressor(estimators=[('rf_model',\n",
              "                               RandomizedSearchCV(cv=5,\n",
              "                                                  estimator=RandomForestRegressor(),\n",
              "                                                  n_jobs=1,\n",
              "                                                  param_distributions={'max_depth': [5,\n",
              "                                                                                     10,\n",
              "                                                                                     15,\n",
              "                                                                                     20,\n",
              "                                                                                     25,\n",
              "                                                                                     30],\n",
              "                                                                       'max_features': ['auto',\n",
              "                                                                                        'sqrt'],\n",
              "                                                                       'min_samples_leaf': [1,\n",
              "                                                                                            2,\n",
              "                                                                                            5,\n",
              "                                                                                            10],\n",
              "                                                                       'min_samples_split': [2,\n",
              "                                                                                             5,\n",
              "                                                                                             10,\n",
              "                                                                                             15,\n",
              "                                                                                             100],\n",
              "                                                                       'n_estimators': [100,\n",
              "                                                                                        200,\n",
              "                                                                                        300,\n",
              "                                                                                        400,\n",
              "                                                                                        500,\n",
              "                                                                                        600,\n",
              "                                                                                        700,\n",
              "                                                                                        800,\n",
              "                                                                                        900,\n",
              "                                                                                        1000,\n",
              "                                                                                        1100,\n",
              "                                                                                        1200]},\n",
              "                                                  random_state=42,\n",
              "                                                  scoring...\n",
              "                                                  param_distributions={'algorithm': ['auto',\n",
              "                                                                                     'ball_tree',\n",
              "                                                                                     'kd_tree',\n",
              "                                                                                     'brute'],\n",
              "                                                                       'leaf_size': [3,\n",
              "                                                                                     4,\n",
              "                                                                                     5,\n",
              "                                                                                     6,\n",
              "                                                                                     7,\n",
              "                                                                                     8,\n",
              "                                                                                     9,\n",
              "                                                                                     10,\n",
              "                                                                                     11,\n",
              "                                                                                     12,\n",
              "                                                                                     13,\n",
              "                                                                                     14,\n",
              "                                                                                     15,\n",
              "                                                                                     16,\n",
              "                                                                                     17,\n",
              "                                                                                     18,\n",
              "                                                                                     19,\n",
              "                                                                                     20,\n",
              "                                                                                     21,\n",
              "                                                                                     22,\n",
              "                                                                                     23,\n",
              "                                                                                     24,\n",
              "                                                                                     25,\n",
              "                                                                                     26,\n",
              "                                                                                     27,\n",
              "                                                                                     28,\n",
              "                                                                                     29],\n",
              "                                                                       'n_neighbors': [3,\n",
              "                                                                                       4,\n",
              "                                                                                       5,\n",
              "                                                                                       6,\n",
              "                                                                                       7,\n",
              "                                                                                       8,\n",
              "                                                                                       9,\n",
              "                                                                                       10,\n",
              "                                                                                       11,\n",
              "                                                                                       12,\n",
              "                                                                                       13,\n",
              "                                                                                       14,\n",
              "                                                                                       15,\n",
              "                                                                                       16,\n",
              "                                                                                       17,\n",
              "                                                                                       18,\n",
              "                                                                                       19]},\n",
              "                                                  random_state=42,\n",
              "                                                  scoring='neg_mean_squared_error',\n",
              "                                                  verbose=3))],\n",
              "                  final_estimator=RandomForestRegressor(n_estimators=15,\n",
              "                                                        random_state=42))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = final_model.predict(x_test)"
      ],
      "metadata": {
        "id": "lhmx5x0pCzoX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (6,6))\n",
        "sns.distplot(y_test-prediction)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "3ac3e71c-9722-4f94-91e8-ffcc771a0891",
        "id": "-Y2Nsy8NCzoY"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAF+CAYAAACYiI0iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcd33v/9dHs2nf5X1NHJN9ISYhgbAVQuBSQqE8SFgucEPT3/0BbWlve6HtD7jhLhTuo+3tBQppGwKUhJ0QaCAECCQliWMHnMVOHDuOY8uLZGvfRtJoPr8/ZsaRlZE0kubozEjv5+Ohh6Rzzsx8lFh6z3c95u6IiIhMVRF2ASIiUpoUECIikpcCQkRE8lJAiIhIXgoIERHJSwEhIiJ5LbmAMLNbzKzTzJ4o0vN9xsx2m9mTZvYPZmbFeF4RkVK35AICuBW4phhPZGZXAi8DLgTOB14CvLIYzy0iUuqWXEC4+31A9+RjZnammf3EzB4xs/vN7OxCnw6oBOJAAogBHUUtWESkRC25gJjGzcCH3f1S4L8AXyjkQe7+IHAvcCz7cbe7PxlYlSIiJSQadgFBM7Na4Erg25OGDxLZc28FbsrzsCPu/noz2wKcA6zLHr/HzK5y9/sDLltEJHRLPiDItJJ63f3iqSfc/XvA92Z47O8BD7n7IICZ/Ri4AlBAiMiSt+S7mNy9H3jWzN4OYBkXFfjwQ8ArzSxqZjEyA9TqYhKRZWHJBYSZ3Q48CLzIzNrN7AbgXcANZvYosBu4tsCn+w7wDPA48CjwqLv/MICyRURKjmm7bxERyWfJtSBERKQ4FBAiIpLXkprF1Nra6ps2bQq7DBGRsvHII4+cdPe2fOeWVEBs2rSJnTt3hl2GiEjZMLPnpjunLiYREclLASEiInkpIEREJC8FhIiI5KWAEBGRvBQQIiKSlwJCRETyUkCIiEheCggREclLASEiInkpIEREJC8FhIiI5BXYZn1mdgvwJqDT3c/Pc/7PydzpLVfHOUCbu3eb2UFgAJgAUu6+Lag6RUQkvyB3c70V+Bzw1Xwn3f2zwGcBzOx3gY+4e/ekS17t7icDrE/K3G3bD+U9/s7LNyxyJSJLU2BdTO5+H9A964UZ1wO3B1WLiIjMXehjEGZWDVwDfHfSYQd+amaPmNmNszz+RjPbaWY7T5w4EWSpIiLLSugBAfwu8Osp3Usvd/cXA28APmhmr5juwe5+s7tvc/dtbW15b4okIiLzUAoBcR1Tupfc/Uj2cyfwfeCyEOoSEVnWQg0IM2sAXgn8YNKxGjOry30NXA08EU6FIiLLV5DTXG8HXgW0mlk78AkgBuDuX8xe9nvAT919aNJDVwLfN7Ncfbe5+0+CqlNERPILLCDc/foCrrmVzHTYyccOABcFU5WIiBSqFMYgRESkBCkgREQkLwWEiIjkpYAQEZG8FBAiIpKXAkJERPJSQIiISF4KCBERyUsBISIieSkgREQkLwWEiIjkpYAQEZG8FBAiIpKXAkJERPJSQIiISF4KCBERyUsBISIieSkgREQkLwWEiIjkpYAQEZG8FBAiIpKXAkJERPJSQIiISF4KCBERyUsBISIieSkgREQkLwWEiIjkpYAQEZG8FBAiIpKXAkJERPJSQIiISF4KCBERyUsBISIieSkgREQkLwWEiIjkFVhAmNktZtZpZk9Mc/5VZtZnZruyHx+fdO4aM9trZvvN7KNB1SgiItOLBvjctwKfA746wzX3u/ubJh8wswjweeB1QDuww8zudPc9QRUqpe+27YfCLkFk2QmsBeHu9wHd83joZcB+dz/g7mPAN4Bri1qciIjMKuwxiCvM7FEz+7GZnZc9thY4POma9uyxvMzsRjPbaWY7T5w4EWStIiLLSpgB8Rtgo7tfBPxf4I75PIm73+zu29x9W1tbW1ELFBFZzkILCHfvd/fB7Nd3ATEzawWOAOsnXboue0xERBZRaAFhZqvMzLJfX5atpQvYAZxlZpvNLA5cB9wZVp0iIstVYLOYzOx24FVAq5m1A58AYgDu/kXg94H/bGYpYAS4zt0dSJnZh4C7gQhwi7vvDqpOERHJL7CAcPfrZzn/OTLTYPOduwu4K4i6RESkMGHPYhIRkRKlgBARkbwUECIikpcCQkRE8lJAiIhIXgoIERHJSwEhIiJ5KSBERCQvBYSIiOSlgJCylEqnuXv3cR5t7w27FJElK8g7yokEYiyV5l+3P8f+zkGqYhHOWVVPPKr3OiLFpt8qKTs7n+tmf+cgV57Zwsj4BDufm8+NC0VkNgoIKTv7OgZpqYnzpgvXsLG5mn/ff5KJtIddlsiSo4CQspJKp3n25BBbVtQCcOWWVnqHxznUPRxyZSJLjwJCysrh7hHGJtKnAmJTSzUAR3tHwixLZElSQEhZ2d85iAFntGYCoq4yRl0iyrE+BYRIsSkgpKzs7xxgXVMVVfHIqWNrGqs42psMsSqRpUkBIWVjIu0c60uyqaXmtOOrGyvpHEgyPpEOqTKRpUkBIWWjZ3iMVNpZUV952vE1DVWkHTr61YoQKSYFhJSNzv5RAFbUJU47vqaxCkDdTCJFpoCQstE5kAmAtikB0VQdozJWoZlMIkWmgJCycWJglIaqGJWxyGnHzYxV9VV0DKgFIVJMCggpG50Doy/oXsppronRMzS2yBWJLG0KCCkLaXc6B5Iv6F7KaaqOM5BMkdJMJpGiUUBIWegbHmd8wllRV5n3fFN1HAd6R8YXtzCRJUwBIWUhN0A9XRdTU00cyEyFFZHiUEBIWTgxkJniOn0XUwyAniG1IESKRQEhZaFneJxEtILqeCTv+fqqGBWmFoRIMSkgpCz0DI/RVB3HzPKerzCjsTqugBApIgWElIXe4XEas91I02mq1lRXkWJSQEjJc/dTLYiZNFXH6RnWGIRIsSggpOT1jYwzmkqfGoieTlNNnMHRFCNjE4tUmcjSpoCQktfek9ljqXHWFkQmQI706vajIsWggJCS196T+YOfW+swncaqePZ6bdonUgwKCCl5uT/4zbO0IOqrMi2IzuyaCRFZmMACwsxuMbNOM3timvPvMrPHzOxxM3vAzC6adO5g9vguM9sZVI1SHtp7RkhEK6iMzfzPta4yCkCnbhwkUhRBtiBuBa6Z4fyzwCvd/QLgU8DNU86/2t0vdvdtAdUnZaK9Z3jGNRA5sUgmRNSCECmOaFBP7O73mdmmGc4/MOnbh4B1QdUi5a29Z2TWGUw59ZUx3XpUpEhKZQziBuDHk7534Kdm9oiZ3TjTA83sRjPbaWY7T5w4EWiREo72npFZZzDl1FVG1YIQKZLAWhCFMrNXkwmIl086/HJ3P2JmK4B7zOwpd78v3+Pd/Way3VPbtm3zwAuWRTWQHGdwNEVDVeEtiNy9q0VkYUJtQZjZhcA/A9e6e1fuuLsfyX7uBL4PXBZOhRK2432Z7qJCAyLTgkjirvcKIgsVWkCY2Qbge8B73P3pScdrzKwu9zVwNZB3JpQsfceyAVFfcEDEGJ9wbbkhUgSBdTGZ2e3Aq4BWM2sHPgHEANz9i8DHgRbgC9nZKansjKWVwPezx6LAbe7+k6DqlNJ2vH9uLYjn10IkaZ5lYZ2IzCzIWUzXz3L+A8AH8hw/AFz0wkfIcpTrYsqtcZhNXSJzXUf/KGevCqwskWWhVGYxieR1rC9JS02cWKSwf6qnWhCa6iqyYAoIKWkd/UlWNVQWfP2p1dSa6iqyYAoIKWnH+pKsqi88IGKRCuoro1osJ1IECggpacf7RubUggBYUV+ptRAiRaCAkJKVHJ+gZ3ic1XMNiLoEHQNqQYgslAJCSlaum2jlHLqYAFprE3Tr3tQiC6aAkJKVWyS3uqFqTo9rqY3TNaiAEFkoBYSUrFwLYq5jEC3Ze1Mnx3VvapGFUEBIycq1IOYcELUJAHUziSyQAkJKVkd/kpp4hNrE3Bb857bYUDeTyMIoIKRkdQ6MznmAGqC1NhsQQ5rqKrIQCggpWZ39SdrqEnN+XHNN5jFqQYgsjAJCSlbnwCgr5tGCaMm2IDQGIbIwCggpSe5OZ/8oK+bRgqhLRIlHKjipLiaRBVFASEkaHE0xMj7Byvq5B4SZ0VwTp1tdTCILooCQktSR3UtpRd3cu5ggu1hOXUwiC6KAkJLUmd1LaT5dTJCZ6to1qC4mkYVQQEhJOpG9n8OKeXQxQWY/JrUgRBZGASElKbdd93xmMUGuBaGAEFkIBYSUpI7+JJWxilP3mJ6rlto4I+MTDI+lilyZyPIxv98+kQDdtv0QDx/spjoe5faHD8/rOVonLZarbtY/c5H5UAtCStJAMjXv1gM8vx+TFsuJzJ8CQkrSQDJFXVVs3o9v0X5MIgumgJCSNJAcp65y/i2IlmwX00kNVIvMmwJCSs5YKs1oKk39ArqYtB+TyMIpIKTkDCTHAairnH8XU3U8QiJaocVyIguggJCS05/MTE2tq5pfC+K27Ye4/eHDVMUi7DzYw23bDxWzPJFlQwEhJacYLQiAmkSUIa2DEJk3BYSUnIFsC2IhYxAANYkIQ6MTxShJZFlSQEjJGUiOE6kwquKRBT1PbSLK4KhaECLzpYCQkjOQTFFXGcXMFvQ8NfEoQ6Mp3L1IlYksLwoIKTn9yfEFraLOqUlESaWdsVS6CFWJLD8KCCk5mRbEwgaoIRMQgLqZROZJASElJ9fFtFC1icwYxtCYBqpF5kMBISUlOT7ByPgE9QvYhykn14IYUgtCZF4KCggz+56Z/Qczm1OgmNktZtZpZk9Mc97M7B/MbL+ZPWZmL5507r1mti/78d65vK6Ur9yd5Io1BgEKCJH5KvQP/heAdwL7zOzTZvaiAh93K3DNDOffAJyV/bgR+EcAM2sGPgFcDlwGfMLMmgp8TSljuXtRF2UMIq4xCJGFKCgg3P1n7v4u4MXAQeBnZvaAmb3fzKb9TXb3+4DuGZ76WuCrnvEQ0Ghmq4HXA/e4e7e79wD3MHPQyBKRu9Vo/Ty32ZgsHq0gHqlQC0JkngruMjKzFuB9wAeA3wL/h0xg3LOA118LTL5lWHv22HTH89V1o5ntNLOdJ06cWEApUgo6c11MRWhBQHY1tQapReal0DGI7wP3A9XA77r7m939m+7+YaA2yAJn4+43u/s2d9/W1tYWZilSBB39SSossxtrMdRoNbXIvBXajv8nd79r8gEzS7j7qLtvW8DrHwHWT/p+XfbYEeBVU47/cgGvI2Wic2CU2kSUigWuos6pTUTpGxkvynOJLDeFdjH99zzHHizC698J/MfsbKaXAn3ufgy4G7jazJqyg9NXZ4/JEtc5MFqUKa45ue02RGTuZmxBmNkqMn3/VWZ2CZB7W1dPprtpRmZ2O5mWQKuZtZOZmRQDcPcvAncBbwT2A8PA+7Pnus3sU8CO7FPd5O4zDXbLEtHZnyzKFNecmkSUodEJ3H3BezuJLDez/Sa+nszA9DrgbycdHwD+crYnd/frZznvwAenOXcLcMtsryFLS+fAKFvaijesVZOIMOHOwGiK+iINfIssFzMGhLt/BfiKmb3N3b+7SDXJMjWWStM9NEbd+uK2IAC6B8cUECJzNFsX07vd/V+BTWb2p1PPu/vf5nmYyLyczN4/uph/yHOL5bqGRtnUWlO05xVZDmZ7q5b7jQp1KqssD8+vgSheC6I224LoGhwr2nOKLBezdTF9Kfv5vy1OObKcdfQXb5uNnJrsjq7dQwoIkbkqdKHcZ8ys3sxiZvZzMzthZu8OujhZXoJoQeTGILoUECJzVug6iKvdvR94E5m9mLYAfx5UUbI8nciuoq4p4jTXWCSzH5O6mETmrtCAyP3G/gfg2+7eF1A9sox1DozSUpsgUlHc9Qo1iQjdQ6NFfU6R5aDQt2o/MrOngBHgP5tZG5AMrixZjjr6k6yoSxT9eWsSUXUxicxDodt9fxS4Etjm7uPAEJmtukWKpnNgNJiAiEfVxSQyD3Pp7D2bzHqIyY/5apHrkWWsc2CUC9Y2FP15axJRjvaOFP15RZa6ggLCzL4GnAnsAnKb6zsKCCmS1ESarsFgWhC1iQjdQ2Paj0lkjgptQWwDzs3unSRSdF1DY6Qd2uori/7cNYkoYxNpBkdTRV1jIbLUFTqL6QlgVZCFyPJ2vC8z52FVEAER12pqkfkotAXRCuwxs4eBU/MF3f3NgVQly87x/ucD4sRAcaek5lZTdw2NaT8mkTkoNCA+GWQRIrltNlY2JHj8SHGf+9SOrprqKjInBQWEu//KzDYCZ7n7z8ysGijOTYNFyAREpMJorQlmHQSgxXIic1ToXkx/AHwH+FL20FrgjqCKkuXneF9mBlNFkVdRw/NjECc1BiEyJ4UOUn8QeBnQD+Du+4AVQRUly09Hf5KVAQxQA8SjFVTFIupiEpmjQgNi1N1P/XZlF8tpyqsUzfH+ZCAzmHJaauMKCJE5KjQgfmVmfwlUmdnrgG8DPwyuLFluOvqSrGoIMCBq4tqPSWSOCg2IjwIngMeBPwTuAv46qKJkeRkaTTEwmgqsiwmguSZO16AGqUXmotBZTGkzuwO4w91PBFyTLDOnprjWF38GU05zTYKnjg8E9vwiS9GMLQjL+KSZnQT2Anuzd5P7+OKUJ8vB5EVyQWmtzXQxabcYkcLN1sX0ETKzl17i7s3u3gxcDrzMzD4SeHWyLDy/SC7YLqaxVJqhsYnZLxYRYPaAeA9wvbs/mzvg7geAdwP/McjCZPk43pcZGwiyBdFcEwfQOITIHMwWEDF3Pzn1YHYcQttiSlF09CepS0SLei/qqVpqswGhmUwiBZstIGb6bdJvmhTF8b5koN1LAC3ZLTy6tZpapGCzvWW7yMz68xw3INjfaFk2OgaSgc5ggue7mLRYTqRwMwaEu2tDPglcR1+Sl57ZEuhr5LqYTmrDPpGCFbpQTiQQ6bTTOTAa6AA1QHU8SmWsQl1MInOggJBQnRwaJZX2QLfZyGmpSaiLSWQOFBASqo7sFNcgt9nIaanVfkwicxHcvEKRWdy2/RBPHsvMgdh1qDfwe0Y318Q5qXUQIgVTC0JC1Z8cB6C+KvhlNS01CY1BiMyBAkJC1T8yjgG1AS6Sy2mti3NyUPsxiRQq0IAws2vMbK+Z7Tezj+Y5/3dmtiv78bSZ9U46NzHp3J1B1inh6R9JUVcZJRLArUanaqtNMDaRpj+ZCvy1RJaCwN62mVkE+DzwOqAd2GFmd7r7ntw17v6RSdd/GLhk0lOMuPvFQdUnpaE/Ob4o3UsAbXWZxXgnBkZpWKTXFClnQbYgLgP2u/uB7O1KvwFcO8P11wO3B1iPlKC+kXHqKhfnj3Vr7fMBISKzCzIg1gKHJ33fnj32Ama2EdgM/GLS4Uoz22lmD5nZW4IrU8LUnxynvnJxJtPlWhCaySRSmFKZ5nod8B13n7xZ/0Z3P2JmZwC/MLPH3f2ZqQ80sxuBGwE2bNiwONVKUYyl0iTH04vW3aMWhMjcBNmCOAKsn/T9uuyxfK5jSveSux/Jfj4A/JLTxycmX3ezu29z921tbW0LrVkW0akprovUxdRYFSNaYWpBiBQoyIDYAZxlZpvNLE4mBF4wG8nMzgaagAcnHWsys0T261Yyd7XbM/WxUt76RjIB0VC9OAFRUWG01ibUghApUGBdTO6eMrMPAXcDEeAWd99tZjcBO909FxbXAd/w0yennwN8yczSZELs05NnP8nS0DecCYjGRZxRlFkLoYAQKUSgYxDufhdw15RjH5/y/SfzPO4B4IIga5Pw9Y5kVjUv1jRXyKyFOKGAECmIVlJLaHqHx6lNRIlFFu+fYWttgpMD2m5DpBAKCAlN38j4oi9Ya6tLcHJwlHRa222IzEYBIaHpHRmncZEGqHPa6hKk0k5vdoBcRKangJBQuDt9I+OLOkANz6+F0EC1yOwUEBKK/pEUY6nFWySXM3k/JhGZmQJCQnGkdwSAhur4or6uWhAihVNASCiO9WUCYrG7mHItiM5+BYTIbBQQEoqjp1oQixsQ9ZVRKmMVdPQnF/V1RcqRAkJCcbQvScRsUe4kN5mZsaq+kg6NQYjMSgEhoTjaO0J9VZQKC/5OclOtqK+ko08tCJHZKCAkFO09IzQt8gB1TqYFoYAQmY0CQkLR3jMcWkCsrE/Q0Z/k9P0hRWQqBYQsuuT4BB39ozTWhHNf6JX1lSTH0/SPpEJ5fZFyoYCQRZebwdQcWguiEkDdTCKzUEDIomvvya6BCGsMoiETEMc1UC0yo1K5J7UsI4d7hgFoWsQ1ELdtP3Tq6+6hzHbfWgshMjO1IGTRtfeMEIvYot4oaLK6ysz7ok6thRCZkQJCFl17zwhrGqtCWQMBEItUUBWLqItJZBYKCFl0h7uHWddUFWoN9VVRdTGJzEIBIYuuvWeEdY3VodZQXxlTQIjMQgEhiyo5PsHJwVHWN4fcgqiM0aEdXUVmpICQRdWencG0NvQuphidA0lSE+lQ6xApZQoIWVSHujMBsaG5JtQ6GqtjpB2Oq5tJZFoKCFlUB09mAmJjS7hjEI3ZNRhHexUQItNRQMiiOtQ9TG0iSktNOKuocxqrMq9/pHc41DpESpkCQhbVwa4hNjRXYyGtgcjJtSCOZLf9EJEXUkDIojrUNcym1nC7lyCzWK6lJs4RdTGJTEsBIYtmIu0c7hkOfYA6Z21TFUd61YIQmY4CQhbN0d4RxiecTSEPUOesaag6tfW4iLyQAkIWzakpriUSEGubqjjSM6I7y4lMQwEhi+Zg1xAAm1pKo4tpTWMVI+MT9AyPh12KSElSQMiiOdQ1TDxawarsHd3CtrYxs5pb3Uwi+SkgZNEc7BpifVMVFRXhTnHNyQVEu6a6iuSlgJBF8+zJITa31oZdxim5/aA0k0kkPwWELIqJtHPw5DBntpXG+ANkbnlaE49wuFurqUXyCTQgzOwaM9trZvvN7KN5zr/PzE6Y2a7sxwcmnXuvme3Lfrw3yDoleO09w4xNpDmzrXRaEGbGxpYanssOnovI6aJBPbGZRYDPA68D2oEdZnanu++Zcuk33f1DUx7bDHwC2AY48Ej2sT1B1SvBOnAi80f4jBJqQQBsaq3mqWMDYZchUpKCbEFcBux39wPuPgZ8A7i2wMe+HrjH3buzoXAPcE1AdcoieObEIABnlFALAmBjSw2He4aZSGsthMhUQQbEWuDwpO/bs8emepuZPWZm3zGz9XN8rJSJZ04M0VgdoznkXVyn2tRSzfiEa6qrSB6BdTEV6IfA7e4+amZ/CHwFeM1cnsDMbgRuBNiwYUPxK5SieOhAF/WVMW7bfijsUk6zMbto77muYdY3l8YKb5FSEWQL4giwftL367LHTnH3LnfP3Rj4n4FLC33spOe42d23ufu2tra2ohQuxXdyYJS22kTYZbxAblX3QQ1Ui7xAkAGxAzjLzDabWRy4Drhz8gVmtnrSt28Gnsx+fTdwtZk1mVkTcHX2mJSh/uQ4A6MpWutKLyBW1CWojFVoJpNIHoF1Mbl7ysw+ROYPewS4xd13m9lNwE53vxP4IzN7M5ACuoH3ZR/bbWafIhMyADe5e3dQtUqwcjOY2mpLa/wBoKLC2Nhcw8EurYUQmSrQMQh3vwu4a8qxj0/6+mPAx6Z57C3ALUHWJ4tjX0dmGumKEtmDaaqNLdXqYhLJQyupJXBPdwwQrbCSm8GUs6m1hue6hklrqqvIaRQQEri9HYOsqEtQEfJ9qKdzRmsNo6m0Nu0TmUIBIYHb1zHAyhLtXgI4a2UdkGnpiMjzFBASqL6RcY71JUt2/AFg68rM6u69CgiR0yggJFC5AeqV9aU3xTWnrjLGmobKU7WKSIYCQgL1dEdmD6ZS7mKCTDdTrlYRyVBASKCe7higJh6hsSoWdikz2rqylv0nBrVpn8gkCggJ1N7jA2xZWYeV6AymnK0r6xhLpbWiWmQSBYQExt3Zc6yfc1fXhV3KrLaemsmkbiaRHAWEBOZoX5K+kXHOXdMQdimz2rIiO5PpuAaqRXIUEBKY3Uf6ADh3dX3IlcyuJhFlc2sNu4/2hV2KSMlQQEhg9hzrxwzOKYMuJoAL1jbw+BEFhEiOAkICs/toP5tba6iOh31fqsJcuK6BY31JOgeSYZciUhIUEBKYPUf7Oa8Mxh9yLlzXCMBjh9WKEAEFhASkd3iMI70jZTH+kHP+2noqDB5TN5MIoICQgOw52g/AeWvKJyCq41HOWlHHY+29YZciUhLKo3NYyk7uXfj5a0u3i+m27YdecKwmEeXx9j7cveQX94kETS0ICcSjh3vZ0FxdsjcJms66piq6hsY41K1bkIooICQQjx7u5aL1jWGXMWebW2sA2H5At0AXUUBI0XUOJDnal+SidaXbvTSdFXUJWmriPHSgK+xSREKngJCiy00TLccWhJlx+RnNPHSgC3ft7CrLmwappei+vv05Kgx2H+lnXxlufvfSM1q46/HjHO4eYUNLddjliIRGLQgpuvaeEVbWVxKPluc/r5ee0QLAQ8+qm0mWt/L8DZaSlU47h3uGWddUvu+8z1pRS0tNnF/vPxl2KSKhUkBIUT3dOUByPM3GMu6aMTNeubWNXz19gtREOuxyREKjgJCi2nmwB4CNzeUbEAC/c85KeofH+e1hraqW5UsBIUX1yHM91CaiZbdAbqqrtrYSrTB+/mRn2KWIhEYBIUW187luNrZUl/02FfWVMS7b3MwvnuoIuxSR0CggpGg6+5Mc7h4p++6lnNecvYKnOwY5eHIo7FJEQqGAkKLZkRt/aKkJuZLieMMFqwH4t8ePhVyJSDi0UE6K5qEDXVTHI6xprAq7lAWZvMvrxuZqvvbgc3zw1VtCrEgkHGpBSNE8eKCLl2xqJlJR3uMPk124roHj/Ume7hgIuxSRRaeAkKLoHEiyv3OQK85sCbuUojp/bQMG3LnraNiliCw6BYQUxUPZ7bGvOGNpBURdZYwtK2r57m/atWhOlh0FhBTFg890UZeIltUtRgv1kk3NHOtL8su9J8IuRWRRBRoQZnaNme01s/1m9tE85//UzPaY2WNm9nMz2zjp3ISZ7cp+3BlknbJwDx3o4rLNzUQjS+89xzmr62mrS3D7wy+8RanIUhbYb7OZRYDPA28AzgWuN7Nzp1z2W7uM4XEAABQASURBVGCbu18IfAf4zKRzI+5+cfbjzUHVKQt3uHuYZ08O8bItrWGXEohIhfGObeu5d28nR3tHwi5HZNEE+XbvMmC/ux9w9zHgG8C1ky9w93vdPXfz34eAdQHWIwH51dOZrpdXbG0LuZLgVMUiuMNf3/EEt20/dNpUWJGlKsiAWAscnvR9e/bYdG4Afjzp+0oz22lmD5nZW4IoUIrjvqdPsLaxijPblsYCuXyaauKctbKWnQe7mUjrTnOyPJREh7GZvRvYBnx20uGN7r4NeCfw92Z25jSPvTEbJDtPnNAg4mIbn0jzwDNdvGJrW9nvvzSbyzY1059Msfe41kTI8hBkQBwB1k/6fl322GnM7LXAXwFvdvfR3HF3P5L9fAD4JXBJvhdx95vdfZu7b2trW7pdHKXqN8/1MDia4pVbl+b4w2QvWlVPfWWU7brTnCwTQQbEDuAsM9tsZnHgOuC02UhmdgnwJTLh0DnpeJOZJbJftwIvA/YEWKvM0717TxCtMK44c+kHRKTCuPyMFvZ1DnK8Pxl2OSKBCywg3D0FfAi4G3gS+Ja77zazm8wsNyvps0At8O0p01nPAXaa2aPAvcCn3V0BUYJ+9mQHl5/RTENVLOxSFsXlm5qJRYxf79PtSGXpC3SzPne/C7hryrGPT/r6tdM87gHggiBrk4V79uQQ+zsHedflG8IuZdFUJ6JcurGJHc/20NmfZEV9ZdgliQSmJAappTz9bE/mZjqvO3dlyJUsrped2UranVsfOBh2KSKB0nbfMm9f3/4cqxsque/p5dXd0lKb4Nw19Xx9+yE++Oot1CT0ayRLk1oQMi+dA0me6xrmnNVLb++lQly1pZW+kXG+vfPw7BeLlCkFhMzLjx8/jgMXrG0Iu5RQbGip4dKNTfzT/c8yltIur7I0KSBkXn702FFW1idYuYwHaT/0mi0c6R3h24+oFSFLkwJC5uxo7wg7DvZwwdrGsEsJ1au2tnHJhkY+/4v9jKYmwi5HpOgUEDJn//bYMSBzO87lzMz4yGu3crQvybd2toddjkjRKSBkTtydb+08zMXrG2mtTYRdTuiuOquVSzc28YV795McVytClhYFhMzJrsO97Osc5B0vWT/7xctArhVxrC/JN3doLEKWFgWEzMm3dh6mKhbhTReuDruUkvGyLS1ctqmZz927n6HRVNjliBSNAkIKNjia4oePHuONF6ymrnJ57L1UCDPjo288mxMDo/zjL58JuxyRolFASMG+vfMwg6Mp3nPFxtkvXmZevKGJt1y8hpvvP8Dh7uHZHyBSBhQQUpCJtPPlXx/k0o1NXLx+eU9vnc5fXHM2ETM+eedu3HXXOSl/CggpyM+e7OBQ9zA3vHxz2KWUrDWNVfzZ1Vv5+VOd/PiJ42GXI7Jg2mVMZuXufO4X+1nfXMXVy2zn1pnctv3QC44lohHOX1vPx3+wm8s2N2sqsJQ1tSBkVj/d08HjR/r449/ZSjSifzIziVQY//vtF9GfHOe/fucxdTVJWVMLQmY0kXb+7p6naa2NMzI2kfdds5zu7FX1/OUbzuaTP9zDP9//LH/wijPCLklkXvR2UGZ0+8OHeOr4AK89ZyWRCgu7nLJw2/ZDxCIVnLemnv9515N84ge7wy5JZF4UEDKtrsFRPnv3Xq44o2XZbus9X2bG2y9dz6qGSm7fcYjfHOoJuySROVNAyLRu+tEehsdSfOot52Gm1sNcxaMVvPeKTdQmorz3Xx5WSEjZUUBIXt/7TTs/2HWUD7/mLLasqAu7nLJVXxXjAy/fTHNtnOtufogf7DoSdkkiBVNAyAvs6xjg/7vjCS7b1MwHX70l7HLKXmN1nO//vy/j4nWN/PE3dvEn3/gtXYOjYZclMivNYpLTnBwc5T99ZQdV8Sh/f93FGpgukuaaOP/6gcv5wi/387lf7Oenezp4zxUbeedlG9jYUnPatflmir3z8g2LVarIKQoIOaVvZJz3f3kHJwZG+eaNV7CmsSrskpaUeLSCP3ntVt504Rr+/mdPc/N9B/jSrw5wwdoGrjqrlZdn7y0hUipsKS3k2bZtm+/cuTPsMspSz9AY7/vywzx5bIDrL1vPi1bVh13SkpKvBXCsb4Tv//YI9z7VyW8P9ZJKO1WxCOubq9jSVsvZq+tPrcRWC0KCYmaPuPu2vOcUEPJc1xDv//IO2ntH+Md3vZiOfvWPL7bk+ATPnhxiX+cg+zsHOZkdo1jfVMUlG5q46drzaKyOh1ylLEUzBYS6mJa5nz/ZwZ9+61HM4LYPXM62Tc1aLR2CyliEc1bXc87qTMutZ3iMx9v7+O3hHu589Cg/2X2cN56/indevpGXbGrStGNZFAqIZWpkbIK/+clT3PrAQc5bU88X3vXiFwyWSniaquO8YmsbV53VyrG+JH0j49zx2yPcsesoZ62o5Z2Xb+Ctl6yjoVo3bpLgqItpmXF3fvTYMf7mJ0/R3jPCFWe2cM15q4hpE76S9s7LNzA8luKHjx7ltu2HeLS9j0S0gqvPW8VVW1q5cksL65qqwy5TypC6mAR3Z8fBHj794yf5zaFezlldzweuWsUZrbVhlyYFqo5HecdLNvCOl2zgiSN93PbwIX66+zg/fPQoAKsbKtncWsPGlhrWN1fRVpugtS6R+VyboKU2rjcCMicKiCUuOT7Bjx47xlceOMjjR/poq0vwmbddyNsuXcc3dxwOuzyZp/PXNnD+mgbOW11Px8Aoz3QOcqR3hMPdw+w63Mvw2ETex9XEI6yor2RVfSXXXryGC9Y1sHVlnYJD8lJALEFjqTS/3n+Sf3v8GPfs6aBvZJwtK2r57285n7e+eC3Vcf1vLzfTTRwwM1Zl/+BPNpZKMziaYjA5zuBoioHRFIPJFH0j43T0J3nkuR4ePNAFQCJawflrG7hwXQMXr2/k/LUNrG6opCoWOTUY7u6MjE9wrC9Je88I7T3D3P1EBz3DY/QOjzE+4aTdSTusb65iXVM1axurOHtVHds2NbG2sUoD62VIYxBlbPIfjb6RcfZ1DLC3Y4BDXcMMjKaoS0R53bkreeuL1/Fc15B+QeWUtDs9Q2On/ti3945wtHeE8Ynn/x4kohU0VscYS6UZSKZIpU//WxExo6E6RmN1jMpoBLNMYA2PpegdHqdveJyJ7N+X1Q2VXL65mavOauOqra2sqDs90CQ8GoNYgsYn0hw4OcjTxwd5umOA4/1JAOoro7xoVR3nrq5ny4paopEKDnUPKxzkNBVmtNQmaKlNcNH6RiBzc6jOgSQbmqs5OTh2qnWQiEaoq4xSWxlldUMl65qqWddUxc+f7KRihn9XaXc6+pMc7BrG3bl/30nu2JUZLzl7VR2v3NrGK7a2cenGJipjkUX5uWVu1IIoI8f7kvxybye/3HuCX+8/ycBoigqDjS01vGhlHVtX1bGyLqEwkAXJt2q7GGtj0u4c70uyr2OAfZ2DHO4ZZnzCqYxVcPnmFs5dU8/m1ho2t9ZQVxklFqkgVlHB4GiK7/6mneGxCYbHUoyMTZAcn2B9czUj2bEWMyNSATWJKHWVMeoSmUCrq4xSm4jy0DNdVMUz3yeiFZiZVqdnhbaS2syuAf4PEAH+2d0/PeV8AvgqcCnQBbzD3Q9mz30MuAGYAP7I3e+e7fWWUkBMpP3UgOP2Z7vZcbCb/Z2DQKa5/qoXtVFhxplttXr3JWVpNJVdPd4xyDMnBukaHDvVJTWbSIVRGa0gHs0MrjuQTjujqTRjE2lmeppYxKhNRNncWsPqhipWN1SyprGKNY2Zz6sbqmiqji2b+6+H0sVkZhHg88DrgHZgh5nd6e57Jl12A9Dj7lvM7Drgb4B3mNm5wHXAecAa4GdmttXd80/NKHETaWcgOU7/SIqhsRQj4xMkxyYYHptgZDzz0TM0RufAKB39SZ7rGmZf5wDJ8TQAdZVR1jRUcc15q9RKkCUjEY1w9qp6zs7u+zWRdnqHx7hgXQMjYxOMTaQZn3Bq4hEeea6H6niU6niEqnhkxllX171kPUNjKQaSqcwAfTKzfmRoNJUduM8M2veOjHOoe5je4fEXjK8AVMUi1FZGiVUYQ5NmheXeVFfGIjhkw8gBoyYRYTyVpjIWob4qRkP24y2XrGF1QxVrm6qoryyfxY2BtSDM7Argk+7++uz3HwNw9/816Zq7s9c8aGZR4DjQBnx08rWTr5vpNYvVgvDsbIy0OxNpJ5V2hsdSDI9OMDSWYnhs4tSMkL6Rcfqzn/tGxulPjvN0xyDJ7B/+kbEJRlPpgl43HqmgrjLKuWvq2bqyjhetquO8NZlfIE1JFQmGuzM8NkHvSGZgfcuKGvpGUgyOZmaApSacAyeGMhfbaZ/IvE8zjExEjKUyv+8jYxP0JzN/E6ZmT11llLWNVaxrqjqtxdJYHaO+KkZjVZyaRIR4tIJ4pIJY9nOua6zYwhqkXgtM/qvWDlw+3TXunjKzPqAle/yhKY9dG1Shl37qHgZHU6cCIc+biVlVxSKn3i2k3WmoirGqvpLKeISqWOajMhYhEa0gFsk0jWMRy3wdqaA6HiExpasoNeE8eriPRw/3FeknFZGpzIyaRJSaROYPN0BbXYS2usSpay7ZML9t2NPup95M9gyPZT+P0zucmUG2/dluBpKpgp8vUpEJo9yMsdzXbXUJ7v+L18yrxpmU/SwmM7sRuDH77aCZ7S3i07cCJ4v4fKVkKf9ssLR/vqX8s4F+vjnbC9h/nffDN053IsiAOAKsn/T9uuyxfNe0Z7uYGsgMVhfyWADc/Wbg5iLVfBoz2zld06vcLeWfDZb2z7eUfzbQz1dKghym3wGcZWabzSxOZtD5zinX3Am8N/v17wO/8MygyJ3AdWaWMLPNwFnAwwHWKiIiUwTWgsiOKXwIuJvMNNdb3H23md0E7HT3O4F/Ab5mZvuBbjIhQva6bwF7gBTwwXKdwSQiUq4CHYNw97uAu6Yc+/ikr5PA26d57P8A/keQ9RUgkK6rErGUfzZY2j/fUv7ZQD9fyVhSK6lFRKR4lsdSQRERmTMFxAzM7LNm9pSZPWZm3zezxrBrKiYze7uZ7TaztJmVxayK2ZjZNWa218z2m9lHw66nmMzsFjPrNLMnwq4lCGa23szuNbM92X+Xfxx2TcViZpVm9rCZPZr92f5b2DUVQgExs3uA8939QuBp4GMh11NsTwBvBe4Lu5BimLS9yxuAc4Hrs9u2LBW3AteEXUSAUsCfufu5wEuBDy6h/3+jwGvc/SLgYuAaM3tpyDXNSgExA3f/qbvnljk+RGY9xpLh7k+6ezEXFobtMmC/ux9w9zHgG8C1IddUNO5+H5nZfkuSux9z999kvx4AniTAHRQWk2cMZr+NZT9KfgBYAVG4/wT8OOwiZEb5tndZEn9glhsz2wRcAmwPt5LiMbOIme0COoF73L3kf7ay32pjoczsZ8CqPKf+yt1/kL3mr8g0f7++mLUVQyE/n0gpMbNa4LvAn7h7f9j1FEt2LdfF2bHM75vZ+e5e0uNJyz4g3P21M503s/cBbwJ+x8twTvBsP98SU/AWLVKazCxGJhy+7u7fC7ueILh7r5ndS2Y8qaQDQl1MM8je8OgvgDe7+3DY9cisCtneRUqUZfay/hfgSXf/27DrKSYza8vNgjSzKjL3yXkq3Kpmp4CY2eeAOuAeM9tlZl8Mu6BiMrPfM7N24Arg37L33Shb2QkFue1dngS+5e67w62qeMzsduBB4EVm1m5mN4RdU5G9DHgP8Jrs79suM3tj2EUVyWrgXjN7jMwbmXvc/Uch1zQrraQWEZG81IIQEZG8FBAiIpKXAkJERPJSQIiISF4KCBGRMjWXDRzNbEN2M8TfZjcgnXWGmAJCZAHM7C1BbChnZq8ysysnfX+rmf1+sV9Hyt6tFL6B41+Tmfp9CZk1Ql+Y7QEKCJGFeQuZnWOLxsyiwKuAK2e5VJa5fBs4mtmZZvYTM3vEzO43s7NzlwP12a8bgKOzPb/WQYhMkt0k7sfAv5P5A32EzI6wa8hsJd4GDAN/ADQDPwL6sh9/CHzB3S81s4uAXcBGdz9kZs8AFwArgFuAVuAE8P7s+VuBJJkN6o5kX3sie82HgRuAfmAbmb21/sLdvxPgfwopE9l/sz9y9/Oz3/8c+H/cfZ+ZXQ78L3d/jZmtBn4KNAE1wGvd/ZGZnlstCJEXOgv4vLufB/QCbyNzH+EPu/ulwH8hEwQPkNnK48/d/eLs7pyVZlYPXAXsBK4ys41AZ3a7lv8LfCV7j5GvA/8w6XXXAVe6+1uBLwJ/l33e+7PnVwMvJ7M32KeD/A8g5Sm70eGVwLezO8d+icy/G4DrgVvdfR3wRuBrZjZjBiz7zfpE8njW3Xdlv34E2MTzv3S5axLTPPYBMltGvAL4n2T6hw3I/ZG/gsxNmgC+Bnxm0mO/nd3xczp3uHsa2GNmKwv+aWQ5qQB63f3iPOduIDte4e4PmlklmZZs50xPJiKnG5309QSZrqTe7Lv53Mc50zz2PjKth43AD4CLyLzrv3+a6ycbmkNdNu1Vsmxlt0d/1szeDpkNELPdnQCHgN/JHj8HqCTThTktBYTI7Gb6pRsgs6Fjzv3Au4F92Xf73WSa8/+ePf8AmRkkAO9i+uCY+rwiLzDNBo7vAm4ws0eB3Tx/V8U/A/4ge/x24H2z3cJAXUwihXkX8I9m9tdkbhf5DeDR7Od/MrM/An7f3Z/Jbludu8/3vwPr3L0n+/2HgS+b2Z+THaSe5vV+CHzHzK7NPkbkBdz9+mlOvWDqq7vvIdP9WTDNYhIRkbzUxSQiInkpIEREJC8FhIiI5KWAEBGRvBQQIiKSlwJCRETyUkCIiEheCggREcnr/wdo6lZGtc5vzAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f308c3b-6d30-4843-8c7f-9e53e88893c3",
        "id": "tNtbmSchCzoZ"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 34927080.13134814\n",
            "MSE: 3032308834369466.5\n",
            "RMSE: 55066403.86269532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('StackedModel.pkl', 'wb')\n",
        "pickle.dump(final_model, file)"
      ],
      "metadata": {
        "id": "UiGSgnbBFx2x"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gsIdoC9FxvD"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}